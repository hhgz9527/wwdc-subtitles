1
00:00:25,076 --> 00:00:27,016
>> 大家好下午好


2
00:00:27,016 --> 00:00:28,686
欢迎来到 509 分会场


3
00:00:29,026 --> 00:00:30,836
我将为大家介绍 AirPlay 2


4
00:00:30,836 --> 00:00:31,656
的多房间音频控制功能


5
00:00:32,195 --> 00:00:33,886
我叫 David Saracino


6
00:00:33,886 --> 00:00:34,666
是 AirPlay 工程团队的


7
00:00:34,666 --> 00:00:36,286
一名成员


8
00:00:36,286 --> 00:00:37,286
今天非常高兴能来到这里


9
00:00:37,286 --> 00:00:38,486
和大家讨论


10
00:00:38,486 --> 00:00:39,576
我们在过去一年来


11
00:00:39,576 --> 00:00:41,126
为 AirPlay 音频新添的众多功能


12
00:00:41,126 --> 00:00:42,756
以及如何怎样才能


13
00:00:42,756 --> 00:00:45,006
将这些功能嵌入你们的 App 里


14
00:00:45,396 --> 00:00:46,466
在我们开始


15
00:00:46,466 --> 00:00:47,686
介绍之前


16
00:00:47,686 --> 00:00:49,056
让我们先来


17
00:00:49,056 --> 00:00:50,926
快速回顾一下当前的 AirPlay


18
00:00:51,226 --> 00:00:52,596
并就我们想把 AirPlay 2 带向何方


19
00:00:52,596 --> 00:00:54,056
做一个说明


20
00:00:54,636 --> 00:00:56,876
应用现在的 AirPlay 你能够


21
00:00:56,876 --> 00:00:58,616
将海量的屏幕画面


22
00:00:58,616 --> 00:01:00,906
音频或视频内容以无线的方式


23
00:01:01,196 --> 00:01:02,826
从任何一部苹果设备


24
00:01:03,066 --> 00:01:04,556
投射到苹果电视或


25
00:01:04,556 --> 00:01:04,956
支持 AirPlay 的音箱中


26
00:01:06,296 --> 00:01:07,596
过去一年来我们着重


27
00:01:07,596 --> 00:01:08,896
在音频版块


28
00:01:08,896 --> 00:01:10,276
新增了许多功能


29
00:01:10,276 --> 00:01:11,166
这也将是我今天演讲的


30
00:01:11,166 --> 00:01:11,506
主要内容


31
00:01:12,996 --> 00:01:14,146
正因为我们在音频版块


32
00:01:14,146 --> 00:01:15,296
新增了这么多功能


33
00:01:15,646 --> 00:01:17,326
我们将它们集合为一个新的整体


34
00:01:17,326 --> 00:01:18,826
叫做 AirPlay 2


35
00:01:21,106 --> 00:01:22,216
所以什么是 AirPlay 2


36
00:01:22,216 --> 00:01:25,166
用 AirPlay 2 你仍然可以


37
00:01:25,166 --> 00:01:27,176
以无线方式将音频内容


38
00:01:27,176 --> 00:01:28,726
从你的 App 发送到


39
00:01:28,726 --> 00:01:29,406
支持 AirPlay 的音箱


40
00:01:29,926 --> 00:01:32,436
但是同时有 AirPlay 2 以后


41
00:01:32,436 --> 00:01:34,986
你可以把那段音频


42
00:01:34,986 --> 00:01:37,346
几乎同步地发送到多个


43
00:01:37,346 --> 00:01:40,546
多个支持 AirPlay 2 的音箱


44
00:01:40,726 --> 00:01:41,986
此外我们还


45
00:01:42,316 --> 00:01:43,346
改进了支持 AirPlay 2 的音箱


46
00:01:43,346 --> 00:01:44,826
存在的音频缓冲问题


47
00:01:44,826 --> 00:01:46,616
以便让音频内容的


48
00:01:46,616 --> 00:01:47,876
播放环境更稳定


49
00:01:47,876 --> 00:01:49,586
更可靠


50
00:01:49,586 --> 00:01:50,416
反应更加灵敏


51
00:01:51,306 --> 00:01:53,946
最后我们还将


52
00:01:53,946 --> 00:01:54,906
介绍多设备控制功能


53
00:01:55,336 --> 00:01:57,016
这一功能将允许


54
00:01:57,016 --> 00:01:58,766
你家中的


55
00:01:58,766 --> 00:02:00,216
多个苹果设备


56
00:02:00,216 --> 00:02:01,226
与房间中的音频流


57
00:02:02,086 --> 00:02:02,206
进行互动


58
00:02:03,336 --> 00:02:04,596
那么都有哪些地方


59
00:02:04,596 --> 00:02:05,106
支持 AirPlay 2 呢？


60
00:02:05,836 --> 00:02:07,406
我非常高兴地告诉你


61
00:02:07,406 --> 00:02:10,015
如果你有 iOS Apple tvOS 或 macOS 应用


62
00:02:10,485 --> 00:02:11,556
你就可以按照我一会儿将


63
00:02:11,556 --> 00:02:13,686
介绍的大致步骤


64
00:02:13,686 --> 00:02:14,686
将 AirPlay 2 功能


65
00:02:14,686 --> 00:02:15,776
运用到你的 App 中


66
00:02:16,326 --> 00:02:19,706
当你这样做之后


67
00:02:19,706 --> 00:02:21,156
你的 App 将能够在一个广阔的


68
00:02:21,156 --> 00:02:23,086
AirPlay  2 播放器生态系统里运行


69
00:02:23,396 --> 00:02:25,136
其中包括 HomePod


70
00:02:25,136 --> 00:02:26,996
最新一代苹果电视


71
00:02:26,996 --> 00:02:28,436
以及即将投放市场的


72
00:02:28,436 --> 00:02:29,206
支持 AirPlay 2 的


73
00:02:29,206 --> 00:02:29,526
第三方音箱


74
00:02:29,966 --> 00:02:32,666
以上就是对于


75
00:02:32,666 --> 00:02:34,126
AirPlay 以及 AirPlay 2


76
00:02:34,126 --> 00:02:34,386
高度概括的介绍


77
00:02:35,306 --> 00:02:36,366
让我们看看本场介绍会


78
00:02:36,366 --> 00:02:38,436
接下来的内容


79
00:02:38,646 --> 00:02:39,696
首先我们将谈一谈


80
00:02:39,786 --> 00:02:41,146
AirPlay 2 的基本嵌入步骤


81
00:02:41,436 --> 00:02:42,636
也就是为了将


82
00:02:42,636 --> 00:02:44,346
AirPlay 2 引入你的 App


83
00:02:44,346 --> 00:02:45,546
需要采取的步骤


84
00:02:46,446 --> 00:02:47,706
之后我们将重点讨论


85
00:02:47,706 --> 00:02:49,036
一些更加高级的播放场景


86
00:02:49,036 --> 00:02:50,356
在你嵌入 AirPlay 2 时


87
00:02:50,356 --> 00:02:51,276
可能会遇到这些问题


88
00:02:52,096 --> 00:02:53,186
最后我们将谈到


89
00:02:53,186 --> 00:02:54,166
AirPlay 2 的


90
00:02:54,166 --> 00:02:55,376
可用性


91
00:02:57,396 --> 00:03:00,026
那么我们先来谈谈


92
00:03:00,026 --> 00:03:00,926
AirPlay 2 的嵌入


93
00:03:02,146 --> 00:03:04,416
为了在 App 中


94
00:03:04,416 --> 00:03:05,886
嵌入 AirPlay 2 


95
00:03:05,956 --> 00:03:07,176
基本上要采取 4 个步骤


96
00:03:08,246 --> 00:03:10,386
第一步必须声明你的 App


97
00:03:10,386 --> 00:03:12,116
提供的是


98
00:03:12,116 --> 00:03:12,476
长音频


99
00:03:12,876 --> 00:03:14,176
我一会儿再解释


100
00:03:14,176 --> 00:03:17,116
什么是长音频


101
00:03:17,276 --> 00:03:18,796
第二步要在 App 中添加一个


102
00:03:18,796 --> 00:03:20,586
AirPlay 选择器


103
00:03:21,686 --> 00:03:23,506
第三步要将


104
00:03:23,506 --> 00:03:24,356
MediaPlayer 框架的


105
00:03:24,356 --> 00:03:25,566
某些部分整合进去


106
00:03:26,126 --> 00:03:29,036
最后一步 要引入


107
00:03:29,036 --> 00:03:30,306
一个带有播放选项的 API


108
00:03:30,306 --> 00:03:31,776
以便充分利用


109
00:03:31,776 --> 00:03:32,906
经过改进的


110
00:03:32,906 --> 00:03:35,016
AirPlay 2 缓冲系统


111
00:03:35,776 --> 00:03:37,036
接下来让我们


112
00:03:37,036 --> 00:03:37,736
逐一讲解这些步骤


113
00:03:39,556 --> 00:03:41,836
首先要声明你自己


114
00:03:41,836 --> 00:03:43,106
提供的是


115
00:03:43,106 --> 00:03:43,596
长音频内容


116
00:03:44,416 --> 00:03:45,596
所以到底什么是


117
00:03:45,596 --> 00:03:46,066
长音频内容


118
00:03:46,546 --> 00:03:48,206
长音频内容就是比如


119
00:03:48,206 --> 00:03:49,796
像是音乐


120
00:03:50,166 --> 00:03:52,946
播客或是有声书


121
00:03:52,946 --> 00:03:54,246
这种音频与苹果电脑短促的


122
00:03:54,246 --> 00:03:56,246
系统声音完全不同


123
00:03:56,736 --> 00:03:58,156
声明你自己是


124
00:03:58,156 --> 00:03:59,726
长音频内容的提供者


125
00:03:59,726 --> 00:04:00,916
非常容易


126
00:04:01,736 --> 00:04:02,916
你只要把  App  中


127
00:04:02,916 --> 00:04:04,986
AVAudioSession  的


128
00:04:05,116 --> 00:04:06,816
路由共享策略


129
00:04:06,816 --> 00:04:07,386
设置为长形的


130
00:04:08,776 --> 00:04:10,166
这里是如何在 iOS 上操作的


131
00:04:10,166 --> 00:04:11,086
代码片段


132
00:04:11,966 --> 00:04:12,916
许多 iOS 开发人员


133
00:04:12,916 --> 00:04:14,786
可能对于设置


134
00:04:14,786 --> 00:04:16,685
分类和模式 


135
00:04:16,685 --> 00:04:18,656
比较熟悉


136
00:04:18,656 --> 00:04:20,226
刚才提到的只是一个新的参数


137
00:04:20,226 --> 00:04:21,305
路由共享策略:.长形


138
00:04:21,706 --> 00:04:22,256
(RouteSharingPolicy:.longform.)


139
00:04:23,526 --> 00:04:24,816
这个参数在


140
00:04:24,816 --> 00:04:26,556
iOS 上已经


141
00:04:26,556 --> 00:04:27,676
存在了一段时间了


142
00:04:27,676 --> 00:04:29,386
AVAudioSession 在苹果电脑操作系统中


143
00:04:29,386 --> 00:04:31,436
是新出现的


144
00:04:31,436 --> 00:04:32,496
我不会在此展示代码片段


145
00:04:32,496 --> 00:04:34,336
不过代码比你在 iOS 上写的


146
00:04:34,336 --> 00:04:35,186
还要简单


147
00:04:35,586 --> 00:04:37,046
你只要把路由共享策略


148
00:04:37,046 --> 00:04:37,966
设置为长形


149
00:04:39,096 --> 00:04:40,866
有关这个路由共享策略的


150
00:04:40,866 --> 00:04:42,956
更多介绍


151
00:04:42,956 --> 00:04:44,446
以及它还能为你的 App


152
00:04:44,446 --> 00:04:45,216
做些什么


153
00:04:45,216 --> 00:04:47,266
例如允许用户在


154
00:04:47,266 --> 00:04:49,086
使用 App 进行 AirPlay 投射时


155
00:04:49,086 --> 00:04:51,716
接电话


156
00:04:51,716 --> 00:04:53,226
使用 AirPlay 2 将音频发送到音箱上


157
00:04:53,646 --> 00:04:54,826
我希望你们能


158
00:04:54,826 --> 00:04:55,916
观看本周早些时候举行的另一个介绍会


159
00:04:55,916 --> 00:04:57,496
它的题目是 What's New in


160
00:04:57,496 --> 00:04:57,846
Audio


161
00:04:57,876 --> 00:05:00,976
好的 以上就是使用 AirPlay 2


162
00:05:00,976 --> 00:05:03,196
需要做的


163
00:05:03,196 --> 00:05:04,266
第一步


164
00:05:04,826 --> 00:05:06,556
第二步是在 App 中添加


165
00:05:06,556 --> 00:05:08,346
AirPlay 选择器


166
00:05:09,016 --> 00:05:11,916
它将使用户能够


167
00:05:11,916 --> 00:05:13,926
在 App 的使用范围内


168
00:05:13,926 --> 00:05:15,386
把他们的内容传输到


169
00:05:15,386 --> 00:05:17,386
AirPlay 音箱


170
00:05:17,716 --> 00:05:18,966
做法很简单


171
00:05:18,966 --> 00:05:21,966
你只要嵌入


172
00:05:22,396 --> 00:05:23,416
一个新的 API


173
00:05:23,416 --> 00:05:24,846
叫做 AVKit'sAVRoutePickerView


174
00:05:25,426 --> 00:05:26,756
把这个界面


175
00:05:26,756 --> 00:05:27,496
加到你的界面层级中


176
00:05:28,776 --> 00:05:30,606
你可能想要控制


177
00:05:30,606 --> 00:05:32,206
这个界面什么时候出现


178
00:05:32,206 --> 00:05:34,376
例如当发现支持 AirPlay 或


179
00:05:34,376 --> 00:05:36,006
AirPlay 2 的音箱时


180
00:05:36,006 --> 00:05:37,366
才让它


181
00:05:37,366 --> 00:05:37,606
出现


182
00:05:38,246 --> 00:05:39,916
你可以嵌入


183
00:05:39,916 --> 00:05:42,046
AVFoundation'sAVRouteDetector


184
00:05:42,146 --> 00:05:43,406
它将在发现音箱


185
00:05:43,406 --> 00:05:44,666
有传输路径时


186
00:05:44,666 --> 00:05:45,206
会通知你


187
00:05:46,636 --> 00:05:49,786
这些 API


188
00:05:49,786 --> 00:05:53,206
在最新的操作系统中都有


189
00:05:53,206 --> 00:05:55,546
包括 macOS iOS


190
00:05:55,546 --> 00:05:56,036
和 Apple tvOS


191
00:05:57,066 --> 00:05:58,276
提醒一下正在使用


192
00:05:58,276 --> 00:05:59,426
MPVolumeView 的


193
00:05:59,426 --> 00:06:01,496
iOS 开发工程师


194
00:06:01,496 --> 00:06:03,066
它将继续工作


195
00:06:03,066 --> 00:06:04,146
但我们鼓励大家


196
00:06:04,146 --> 00:06:05,086
使用这些新的 API


197
00:06:05,636 --> 00:06:08,236
以上是如何在 App 中


198
00:06:08,236 --> 00:06:09,646
充分利用 AirPlay 2


199
00:06:09,646 --> 00:06:10,866
的第二个步骤


200
00:06:11,576 --> 00:06:13,426
你要做的第三件事是


201
00:06:13,426 --> 00:06:14,786
将你的 App


202
00:06:14,786 --> 00:06:15,866
与 MediaPlayer 框架下的部分内容进行


203
00:06:15,866 --> 00:06:16,326
整合


204
00:06:16,836 --> 00:06:18,036
这部分内容比较多


205
00:06:18,036 --> 00:06:18,986
所以我今天


206
00:06:18,986 --> 00:06:20,566
只重点讲


207
00:06:20,566 --> 00:06:20,936
两件事


208
00:06:20,936 --> 00:06:23,416
这些事情


209
00:06:24,036 --> 00:06:26,496
这些 API 将让你


210
00:06:26,496 --> 00:06:27,726
能够在锁屏上


211
00:06:27,726 --> 00:06:29,896
或者是被 AirPlay 投射的苹果电视上


212
00:06:29,896 --> 00:06:31,836
显示正在播放的专辑图片


213
00:06:32,776 --> 00:06:33,906
等信息


214
00:06:34,286 --> 00:06:35,556
同时它们将


215
00:06:35,556 --> 00:06:37,526
让你能够接收


216
00:06:37,526 --> 00:06:39,716
来自网络中其他设备


217
00:06:39,716 --> 00:06:42,056
或是耳机等配件的


218
00:06:42,056 --> 00:06:43,846
播放以及暂停


219
00:06:43,846 --> 00:06:44,336
命令 


220
00:06:44,916 --> 00:06:47,066
我们需要的两个 API


221
00:06:47,066 --> 00:06:48,646
我们希望你能


222
00:06:48,646 --> 00:06:49,036
嵌入它们


223
00:06:49,796 --> 00:06:50,516
第一个是


224
00:06:50,516 --> 00:06:52,446
MPRemoteCommandCenter


225
00:06:52,446 --> 00:06:53,676
它将允许你接收


226
00:06:53,676 --> 00:06:55,996
远程命令


227
00:06:56,276 --> 00:06:58,486
第二个是 MPNowPlayingInfoCenter


228
00:06:58,486 --> 00:06:59,476
它将允许你


229
00:06:59,476 --> 00:07:01,076
将正在播放的曲目


230
00:07:01,076 --> 00:07:02,456
通知给元数据系统


231
00:07:02,626 --> 00:07:05,456
好的 以上就是


232
00:07:05,456 --> 00:07:06,676
你在 App 中使用 AirPlay 2


233
00:07:06,676 --> 00:07:08,086
需要做的


234
00:07:08,086 --> 00:07:08,336
第三件事


235
00:07:08,986 --> 00:07:10,536
第四件事是


236
00:07:10,536 --> 00:07:11,946
你应该嵌入一个


237
00:07:11,946 --> 00:07:13,846
控制播放的 API


238
00:07:13,886 --> 00:07:15,666
以充分利用


239
00:07:15,666 --> 00:07:16,916
AirPlay 2 的升级版缓冲系统


240
00:07:18,106 --> 00:07:18,926
为了让大家更好地理解


241
00:07:18,926 --> 00:07:20,786
我们来深入了解一下


242
00:07:20,786 --> 00:07:22,136
AirPlay 的音频和


243
00:07:22,136 --> 00:07:24,526
缓冲级别


244
00:07:24,646 --> 00:07:26,556
首先来了解一下


245
00:07:26,556 --> 00:07:26,876
现在的 AirPlay 是如何工作的


246
00:07:28,076 --> 00:07:30,266
当前的 AirPlay 实际上是


247
00:07:30,266 --> 00:07:32,506
一个实时的音频流


248
00:07:32,506 --> 00:07:33,826
接收的音箱只需要


249
00:07:33,826 --> 00:07:35,486
几秒钟的缓冲时间


250
00:07:35,486 --> 00:07:36,506
就可以流畅播放了


251
00:07:37,066 --> 00:07:39,936
目前这个功能对于


252
00:07:39,936 --> 00:07:41,906
单个音箱来说表现很好


253
00:07:41,906 --> 00:07:43,626
在播放海量内容时


254
00:07:43,626 --> 00:07:44,116
也工作顺畅


255
00:07:45,136 --> 00:07:48,256
不过


256
00:07:48,256 --> 00:07:49,646
如果我们只重点针对长音频


257
00:07:49,646 --> 00:07:51,526
进一步开发例如音乐播客


258
00:07:51,596 --> 00:07:53,516
或者是有声书


259
00:07:53,516 --> 00:07:56,356
我们可能会取得更大进步


260
00:07:56,526 --> 00:07:58,616
让我们来谈谈


261
00:07:58,616 --> 00:08:00,586
AirPlay 2 中经过改进的缓冲系统


262
00:08:01,186 --> 00:08:03,386
我所说的经过改进的


263
00:08:03,386 --> 00:08:04,946
AirPlay 2 缓冲系统是指什么呢？


264
00:08:05,536 --> 00:08:09,326
正如名称所指的


265
00:08:09,326 --> 00:08:11,986
我们使支持 AirPlay 2 的音箱


266
00:08:11,986 --> 00:08:13,516
增加了非常大的缓冲能力


267
00:08:13,726 --> 00:08:14,566
现在我希望你能就此认真思考


268
00:08:14,566 --> 00:08:16,796
几分钟 而不是几秒钟


269
00:08:17,816 --> 00:08:18,746
此外我们能够


270
00:08:18,746 --> 00:08:20,226
以比实时还要快的速度


271
00:08:20,226 --> 00:08:21,486
将音频内容


272
00:08:21,486 --> 00:08:22,596
从你的 App 传输到音箱上


273
00:08:23,126 --> 00:08:25,416
这项改进的优势


274
00:08:25,416 --> 00:08:26,096
显而易见


275
00:08:27,396 --> 00:08:28,956
AirPlay 音箱的巨大缓冲能力


276
00:08:28,956 --> 00:08:30,126
能够大幅增加


277
00:08:30,126 --> 00:08:32,236
AirPlay 的


278
00:08:32,236 --> 00:08:33,135
稳定性


279
00:08:33,916 --> 00:08:35,106
同时能对抗


280
00:08:35,106 --> 00:08:36,586
更多的常见网络故障


281
00:08:36,586 --> 00:08:38,046
例如你在走路外出倒垃圾


282
00:08:38,046 --> 00:08:39,226
或走到屋内的死角


283
00:08:39,226 --> 00:08:40,326
甚至是


284
00:08:40,326 --> 00:08:41,405
在微波爆米花时


285
00:08:43,336 --> 00:08:44,606
此外它还能


286
00:08:44,606 --> 00:08:46,106
提供更加富有回应性的


287
00:08:46,106 --> 00:08:46,806
播放体验


288
00:08:47,556 --> 00:08:48,876
目前的 AirPlay


289
00:08:48,876 --> 00:08:50,016
所拥有的实时属性


290
00:08:50,016 --> 00:08:51,816
意味着存在一个与 AirPlay 音箱


291
00:08:51,816 --> 00:08:53,376
缓冲级别有关的


292
00:08:53,376 --> 00:08:54,196
固定的输出延迟时间


293
00:08:55,346 --> 00:08:57,046
所以当你按下播放键


294
00:08:57,046 --> 00:08:58,386
AirPlay 2 将更快


295
00:08:58,386 --> 00:08:58,776
开始播放


296
00:08:58,776 --> 00:08:59,726
当你按下一曲按键


297
00:08:59,726 --> 00:09:00,676
它也会更快地做出反应


298
00:09:01,726 --> 00:09:04,476
这将带来


299
00:09:04,476 --> 00:09:06,366
更好的用户体验


300
00:09:06,366 --> 00:09:08,586
这也是为什么我们


301
00:09:08,586 --> 00:09:09,506
如此兴奋地向大家介绍


302
00:09:09,506 --> 00:09:10,196
新的缓冲系统


303
00:09:10,716 --> 00:09:14,106
为了充分利用


304
00:09:14,106 --> 00:09:15,336
经过改进的缓冲系统


305
00:09:15,336 --> 00:09:16,766
你应该嵌入


306
00:09:16,766 --> 00:09:17,466
几组 API 中的一组


307
00:09:18,646 --> 00:09:20,656
第一组是 AVPlayer


308
00:09:20,656 --> 00:09:21,416
以及 AVQueuePlayer


309
00:09:21,606 --> 00:09:23,696
AVPlayer 拥有一组


310
00:09:23,696 --> 00:09:23,976
播放 API


311
00:09:24,686 --> 00:09:26,016
它们已经推出了一段时间


312
00:09:26,016 --> 00:09:27,686
并且是通往 AirPlay 2


313
00:09:27,686 --> 00:09:29,196
新缓冲系统


314
00:09:29,196 --> 00:09:29,906
最便捷的路径


315
00:09:31,286 --> 00:09:33,146
第二组 API


316
00:09:33,146 --> 00:09:34,556
是我们今天要介绍的


317
00:09:34,556 --> 00:09:35,736
新事物


318
00:09:35,736 --> 00:09:37,766
叫做 AVSampleBufferAudio Renderer


319
00:09:37,766 --> 00:09:38,796
以及 AVSampleBufferRender


320
00:09:38,796 --> 00:09:39,456
Synchronizer


321
00:09:40,896 --> 00:09:42,536
它们会让


322
00:09:42,536 --> 00:09:44,786
App 的灵活性


323
00:09:45,396 --> 00:09:45,466
得到提升


324
00:09:46,096 --> 00:09:47,276
那么 让我们逐一来


325
00:09:47,276 --> 00:09:50,326
谈谈这些 API


326
00:09:50,326 --> 00:09:51,516
首先是 AVPlayer 和 AVQueuePlayer


327
00:09:52,666 --> 00:09:53,646
正如我所说


328
00:09:53,646 --> 00:09:54,896
它们已经推出了一段时间


329
00:09:54,896 --> 00:09:56,516
在 iOS  4 时就有了


330
00:09:57,596 --> 00:09:59,026
正因如此


331
00:09:59,026 --> 00:10:00,316
在开发者网站上有大量的存档记录


332
00:10:00,316 --> 00:10:01,716
还有很多的


333
00:10:01,716 --> 00:10:02,516
样本代码


334
00:10:03,046 --> 00:10:04,286
所以如果你想要获得详细的信息


335
00:10:04,286 --> 00:10:06,326
我鼓励你去


336
00:10:06,326 --> 00:10:07,896
查看开发者的网站


337
00:10:07,896 --> 00:10:09,466
在这里我只打算给出


338
00:10:09,466 --> 00:10:10,646
关于这些 API 的高度概括的


339
00:10:10,646 --> 00:10:11,486
介绍


340
00:10:12,366 --> 00:10:14,316
我接下来要做的


341
00:10:14,316 --> 00:10:15,876
是将粗略介绍一遍


342
00:10:15,876 --> 00:10:17,336
如何用这个 API 


343
00:10:17,336 --> 00:10:17,666
建立 App


344
00:10:18,196 --> 00:10:19,236
这里是你的 ClientApp


345
00:10:19,236 --> 00:10:20,526
如果你想用 AVPlayer


346
00:10:20,526 --> 00:10:21,706
或 AVQueuePlayer 来建立 App


347
00:10:21,706 --> 00:10:23,186
首先要做的就是


348
00:10:23,186 --> 00:10:24,356
将这些对象中的一个


349
00:10:24,356 --> 00:10:25,926
实例化


350
00:10:27,246 --> 00:10:28,716
我在这里使用的是 AVQueuePlayer


351
00:10:28,716 --> 00:10:29,916
如果你用 AVPlayer 的话


352
00:10:29,916 --> 00:10:31,196
步骤是一样的


353
00:10:31,686 --> 00:10:35,576
接下来你要把


354
00:10:35,576 --> 00:10:37,006
指向你播放内容的 URL


355
00:10:37,006 --> 00:10:38,616
当然这个内容可以是


356
00:10:38,616 --> 00:10:40,316
存在本地的


357
00:10:40,316 --> 00:10:41,296
或是在云端的


358
00:10:41,296 --> 00:10:41,586
它可以是在远端的


359
00:10:41,586 --> 00:10:43,296
你把这个 URL


360
00:10:43,296 --> 00:10:45,006
放在 AVAsset 里


361
00:10:45,006 --> 00:10:46,766
再把这个 AVAsset


362
00:10:46,766 --> 00:10:48,246
放在


363
00:10:48,246 --> 00:10:48,766
AVPlayerItem 里面


364
00:10:50,296 --> 00:10:51,786
接下来你要把


365
00:10:51,786 --> 00:10:53,146
这个 AVPlayerItem


366
00:10:53,146 --> 00:10:53,646
放到 AVQueuePlayer


367
00:10:54,246 --> 00:10:56,636
在你把它移交过去之后


368
00:10:56,636 --> 00:10:57,466
你就准备好可以启动


369
00:10:57,466 --> 00:10:57,846
播放了


370
00:10:57,966 --> 00:11:00,536
你只需简单将


371
00:11:00,536 --> 00:11:01,366
AVQueuePlayer 的 rate 设置为 1


372
00:11:01,366 --> 00:11:03,856
它就会开始


373
00:11:03,856 --> 00:11:05,146
下载音频数据


374
00:11:05,146 --> 00:11:07,496
然后在


375
00:11:08,036 --> 00:11:10,266
音箱中


376
00:11:10,266 --> 00:11:10,806
播放


377
00:11:11,206 --> 00:11:15,876
这就是对 AVPlayer 和 AVQueuePlayer 的


378
00:11:15,876 --> 00:11:17,346
简要介绍


379
00:11:17,346 --> 00:11:18,466
以上内容同样适用于


380
00:11:18,466 --> 00:11:19,876
视频文件


381
00:11:20,546 --> 00:11:21,316
如果你想播放


382
00:11:21,316 --> 00:11:22,686
视频内容


383
00:11:22,686 --> 00:11:23,986
用 AVPlayer 和 AVQueuePlayer


384
00:11:23,986 --> 00:11:24,446
也能轻松搞定


385
00:11:25,026 --> 00:11:29,056
再强调一遍


386
00:11:29,056 --> 00:11:31,036
AirPlay 2 最简单的使用方法


387
00:11:31,036 --> 00:11:31,866
就是通过这些 API


388
00:11:32,666 --> 00:11:34,486
不过我们也明白


389
00:11:34,486 --> 00:11:35,346
可能不是人人都这么认为


390
00:11:35,746 --> 00:11:37,146
可能有这样一类


391
00:11:37,146 --> 00:11:38,166
音频播放 App


392
00:11:38,166 --> 00:11:39,736
它们想要有


393
00:11:39,736 --> 00:11:40,936
自己的 IO


394
00:11:41,446 --> 00:11:43,916
自己的 DRM


395
00:11:43,976 --> 00:11:46,506
甚至在媒体数据被渲染之前


396
00:11:46,596 --> 00:11:47,456
对它进行预处理


397
00:11:47,566 --> 00:11:48,866
这些 App 需要更多的灵活性


398
00:11:48,866 --> 00:11:50,216
这是刚才那些 API


399
00:11:50,346 --> 00:11:50,716
无法提供的


400
00:11:51,176 --> 00:11:54,416
对于这些开发者


401
00:11:54,416 --> 00:11:55,986
我们想介绍以下这些新类别


402
00:11:56,536 --> 00:11:58,616
AVSampleBufferAudio Renderer 和


403
00:11:58,616 --> 00:11:59,586
AVSampleBufferRender


404
00:11:59,586 --> 00:12:00,236
Synchronizer


405
00:12:01,766 --> 00:12:03,646
用这组新的 API


406
00:12:03,646 --> 00:12:05,006
来设置播放的话


407
00:12:05,006 --> 00:12:06,566
你的 App 就要承担额外的责任


408
00:12:07,786 --> 00:12:09,536
首先你的 App


409
00:12:09,536 --> 00:12:10,846
要负责找到播放内容的来源


410
00:12:10,846 --> 00:12:11,666
并对其解析


411
00:12:12,156 --> 00:12:13,286
你需要到源头去获取内容


412
00:12:13,286 --> 00:12:14,796
不管是下载还是从光盘上读取


413
00:12:14,796 --> 00:12:16,396
都可以


414
00:12:17,046 --> 00:12:18,596
然后你的 App 必须去解析它


415
00:12:18,596 --> 00:12:20,806
并得到原始音频数据


416
00:12:20,806 --> 00:12:22,786
原始音频数据缓冲到 API


417
00:12:22,926 --> 00:12:23,436
再进行渲染


418
00:12:24,936 --> 00:12:26,086
这有点类似于


419
00:12:26,086 --> 00:12:27,386
AudioQueue 但它在


420
00:12:27,386 --> 00:12:28,806
更强缓冲能力下 会表现得更好


421
00:12:28,806 --> 00:12:31,776
例如拥有更好缓冲系统的


422
00:12:31,916 --> 00:12:32,526
AirPlay


423
00:12:32,826 --> 00:12:35,366
正因为这些都是新的内容


424
00:12:35,366 --> 00:12:36,486
我们这场介绍会余下的时间


425
00:12:36,486 --> 00:12:37,666
都将用来


426
00:12:37,976 --> 00:12:38,356
介绍它们


427
00:12:38,496 --> 00:12:42,676
好的 让我们来看一下


428
00:12:42,676 --> 00:12:44,156
一个简单的框图


429
00:12:44,156 --> 00:12:45,436
介绍如何用这些 API


430
00:12:45,436 --> 00:12:45,906
来建立 App


431
00:12:47,096 --> 00:12:48,706
再一次使用你的 Client App


432
00:12:49,436 --> 00:12:50,286
建立 App 你首先


433
00:12:50,286 --> 00:12:51,376
要做的事


434
00:12:51,376 --> 00:12:52,046
就是你需要对


435
00:12:52,046 --> 00:12:52,896
AVSampleBufferRenderSynchronizer


436
00:12:53,286 --> 00:12:54,486
以及


437
00:12:54,486 --> 00:12:55,776
AVSampleBufferAudio Renderer


438
00:12:55,776 --> 00:12:57,176
进行实例化


439
00:12:58,156 --> 00:12:59,656
在这些分类当中


440
00:12:59,656 --> 00:13:01,516
类型 AudioRenderer


441
00:13:01,516 --> 00:13:02,436
负责


442
00:13:02,436 --> 00:13:04,226
对音频进行解析


443
00:13:04,226 --> 00:13:05,686
类型 Synchronizer 负责


444
00:13:05,686 --> 00:13:06,766
建立媒体的


445
00:13:06,766 --> 00:13:08,146
时间线


446
00:13:09,416 --> 00:13:10,506
你可能有充足的理由去问


447
00:13:10,506 --> 00:13:11,536
为什么它们被分成两类


448
00:13:11,536 --> 00:13:12,586
为什么不把它们


449
00:13:12,586 --> 00:13:13,506
合二为一


450
00:13:13,626 --> 00:13:14,566
我向你保证


451
00:13:14,566 --> 00:13:15,146
这么做有充足的理由


452
00:13:15,146 --> 00:13:16,046
但我们晚一点再告诉你原因


453
00:13:16,306 --> 00:13:17,126
不过


454
00:13:17,616 --> 00:13:19,106
AudioRenderer 它确实


455
00:13:19,106 --> 00:13:20,066
负责解析音频


456
00:13:20,186 --> 00:13:21,676
Synchronizer 是建立


457
00:13:21,676 --> 00:13:23,636
媒体的时间线


458
00:13:24,156 --> 00:13:25,646
所以当你实例化了之后


459
00:13:25,646 --> 00:13:27,786
你可以把 AudioRenderer


460
00:13:27,976 --> 00:13:28,866
添加到 Synchronizer


461
00:13:29,436 --> 00:13:31,596
这么做是告诉 AudioRenderer


462
00:13:31,596 --> 00:13:33,006
要去跟从由 Synchronizer 建立的


463
00:13:33,006 --> 00:13:34,816
媒体时间线


464
00:13:34,816 --> 00:13:38,386
现在当你开始和


465
00:13:38,386 --> 00:13:39,816
AVSampleBufferAudio Renderer 


466
00:13:39,866 --> 00:13:40,836
开始工作


467
00:13:40,836 --> 00:13:41,766
它会告诉你


468
00:13:41,766 --> 00:13:43,656
它在什么时间需要更多的媒体数据


469
00:13:44,376 --> 00:13:45,686
而当它告诉你它需要


470
00:13:45,686 --> 00:13:46,906
更多的媒体数据时


471
00:13:46,906 --> 00:13:48,686
作为回应 你应该反馈给它


472
00:13:49,776 --> 00:13:50,796
给它提供一些音频数据


473
00:13:51,416 --> 00:13:54,016
完成这些之后


474
00:13:54,016 --> 00:13:55,676
你就可以把 Synchronizer 的


475
00:13:55,676 --> 00:13:57,066
Rate 设为 1


476
00:13:57,066 --> 00:13:57,706
然后开始播放


477
00:13:58,216 --> 00:14:00,596
在你把 Synchronizer 的 rate 设为 1 之后


478
00:14:00,596 --> 00:14:02,476
音频数据将开始


479
00:14:02,476 --> 00:14:04,016
从 AudioRenderer 中


480
00:14:04,016 --> 00:14:04,676
流出


481
00:14:05,226 --> 00:14:09,136
这就是基本的非常概括的


482
00:14:09,136 --> 00:14:10,356
介绍教你如何用


483
00:14:10,356 --> 00:14:11,646
AVSampleBufferAudio Renderer 和


484
00:14:11,646 --> 00:14:13,216
AVSampleBufferRender


485
00:14:13,216 --> 00:14:14,036
Synchronizer


486
00:14:14,036 --> 00:14:14,656
来建立播放引擎


487
00:14:15,136 --> 00:14:16,056
现在我要邀请我的同事


488
00:14:16,056 --> 00:14:17,506
Adam Sonnanstine 上台


489
00:14:17,506 --> 00:14:19,236
为大家做一个演示


490
00:14:20,016 --> 00:14:21,196
鼓掌


491
00:14:21,196 --> 00:14:21,776
>>  谢谢 David


492
00:14:23,156 --> 00:14:24,566
今天我很高兴在这里


493
00:14:24,566 --> 00:14:26,836
为大家演示 AirPlay 2


494
00:14:26,836 --> 00:14:28,356
以及它更强大的可靠性


495
00:14:28,356 --> 00:14:29,016
和稳定性


496
00:14:29,066 --> 00:14:31,236
我将用这个


497
00:14:31,236 --> 00:14:32,726
我们开发的


498
00:14:32,726 --> 00:14:33,256
样品 App 来演示


499
00:14:33,256 --> 00:14:35,206
这个 App


500
00:14:35,266 --> 00:14:37,416
在 WWDC 结束后


501
00:14:37,416 --> 00:14:38,626
很快就会在样本代码中提供出来


502
00:14:39,316 --> 00:14:40,916
我们在台上还准备了一台苹果电视


503
00:14:40,916 --> 00:14:42,336
用于演示


504
00:14:42,646 --> 00:14:44,576
分别用 AirPlay 和 AirPlay 2


505
00:14:44,576 --> 00:14:46,626
两种方式


506
00:14:46,626 --> 00:14:48,236
将播放内容从手机传输到苹果电视上


507
00:14:48,566 --> 00:14:50,136
我们先来看看这个 App


508
00:14:50,136 --> 00:14:51,816
你可以看到它只是一个简单的


509
00:14:51,816 --> 00:14:53,266
精简的音乐播放器的


510
00:14:53,266 --> 00:14:54,266
交互界面


511
00:14:54,816 --> 00:14:57,156
这里可以看到


512
00:14:57,156 --> 00:14:59,226
控制中心的整合


513
00:14:59,566 --> 00:15:01,066
因为我嵌入了 MediaPlayer 的 API


514
00:15:01,126 --> 00:15:02,786
就像 David 刚才


515
00:15:02,786 --> 00:15:03,496
提到的那样


516
00:15:03,496 --> 00:15:05,106
我要开始尝试


517
00:15:05,106 --> 00:15:05,946
播放了


518
00:15:05,946 --> 00:15:07,736
你能够听到它


519
00:15:08,346 --> 00:15:10,426
我先用 AirPlay 投射到我的苹果电视上


520
00:15:10,996 --> 00:15:16,216
这款 App 现在还没有


521
00:15:16,216 --> 00:15:18,486
优化到 AirPlay 2


522
00:15:18,486 --> 00:15:19,646
我只是想给大家看一下


523
00:15:19,716 --> 00:15:21,746
AirPlay 的表现


524
00:15:21,746 --> 00:15:23,036
大概是什么样子


525
00:15:23,726 --> 00:15:25,806
我希望你们想象一下


526
00:15:25,806 --> 00:15:27,676
自己正坐在客厅的


527
00:15:27,956 --> 00:15:29,616
沙发上


528
00:15:29,616 --> 00:15:31,346
享受这段音乐


529
00:15:31,346 --> 00:15:32,646
音乐从我的手机


530
00:15:32,646 --> 00:15:34,706
流向我的苹果电视


531
00:15:34,706 --> 00:15:36,296
现在我决定


532
00:15:36,436 --> 00:15:37,786
把手机放在口袋里


533
00:15:37,786 --> 00:15:39,476
出门倒垃圾


534
00:15:40,366 --> 00:15:42,816
这一过程中可能会走出


535
00:15:42,816 --> 00:15:45,236
我的 Wi-Fi 覆盖区


536
00:15:45,236 --> 00:15:46,746
我要用这个口袋模拟出门的效果


537
00:15:46,806 --> 00:15:48,976
这个口袋能阻隔


538
00:15:48,976 --> 00:15:50,596
里面东西发射的所有讯号


539
00:15:50,596 --> 00:15:52,836
电磁辐射无法进出


540
00:15:52,836 --> 00:15:55,006
这个口袋


541
00:15:55,006 --> 00:15:56,176
包括 Wi-Fi 信号


542
00:15:56,876 --> 00:16:00,166
我将带上我的手机走出门


543
00:16:00,166 --> 00:16:03,096
然后你能听到


544
00:16:03,096 --> 00:16:05,766
音乐几乎是立刻


545
00:16:05,766 --> 00:16:06,656
中断了


546
00:16:07,016 --> 00:16:07,996
你或许以前也有过


547
00:16:07,996 --> 00:16:09,826
类似的经历


548
00:16:09,826 --> 00:16:11,046
如果你正在我家做客


549
00:16:11,046 --> 00:16:12,376
享受着这段音乐


550
00:16:12,626 --> 00:16:13,586
你可能会认为


551
00:16:13,586 --> 00:16:14,906
我不是一个称职的主人


552
00:16:15,716 --> 00:16:17,826
让我们继续


553
00:16:17,826 --> 00:16:19,146
我现在暂停音乐


554
00:16:20,696 --> 00:16:23,446
让我们换到 Xcode 界面


555
00:16:23,446 --> 00:16:24,896
我将向你们展示


556
00:16:25,246 --> 00:16:27,606
如何通过几个简单的步骤


557
00:16:27,856 --> 00:16:30,446
来让这个 App 升级到


558
00:16:30,446 --> 00:16:30,736
AirPlay 2


559
00:16:31,716 --> 00:16:33,876
来看 Xcode 界面


560
00:16:33,876 --> 00:16:35,636
这里有一段非常短的代码片段


561
00:16:35,636 --> 00:16:37,076
是我的 App 的


562
00:16:37,076 --> 00:16:38,316
其余部分放在了


563
00:16:38,526 --> 00:16:39,386
别的文件中


564
00:16:39,776 --> 00:16:41,416
这里有一个


565
00:16:41,876 --> 00:16:43,946
App 其余部分使用的函数


566
00:16:44,176 --> 00:16:45,956
可用来抓取目标


567
00:16:45,956 --> 00:16:48,486
实现音频的


568
00:16:48,486 --> 00:16:49,016
播放


569
00:16:49,506 --> 00:16:50,466
它基本上


570
00:16:50,466 --> 00:16:50,866
是一个工厂函数


571
00:16:50,866 --> 00:16:52,446
这个函数会返回一个


572
00:16:52,446 --> 00:16:53,956
符合某种协议的目标


573
00:16:53,956 --> 00:16:54,956
相关协议我在 App 的其他地方


574
00:16:54,956 --> 00:16:55,186
已经进行了定义


575
00:16:55,606 --> 00:16:56,246
我们不需要探讨细节


576
00:16:56,246 --> 00:16:57,836
但它定义出了


577
00:16:57,836 --> 00:16:59,356
诸如播放暂停等


578
00:16:59,356 --> 00:17:00,966
动作的方法


579
00:17:00,966 --> 00:17:02,326
这是一个播放器所


580
00:17:02,326 --> 00:17:02,576
需要的


581
00:17:03,276 --> 00:17:04,406
我们有一个现行的


582
00:17:04,406 --> 00:17:06,026
对于这个协议的实现


583
00:17:06,106 --> 00:17:07,715
刚刚在我们看到的演示中


584
00:17:07,715 --> 00:17:08,396
使用到了


585
00:17:08,396 --> 00:17:10,516
我们现在要做的


586
00:17:10,516 --> 00:17:11,715
是创建一个全新的


587
00:17:11,715 --> 00:17:14,566
音频播放器的实现


588
00:17:14,566 --> 00:17:15,705
我将把它命名为


589
00:17:15,705 --> 00:17:17,536
SampleBufferAudioPlayer


590
00:17:17,536 --> 00:17:19,425
因为我们将会用到


591
00:17:19,425 --> 00:17:21,356
AVSampleBufferAudio


592
00:17:21,356 --> 00:17:21,786
Renderer


593
00:17:21,786 --> 00:17:23,596
我将先行


594
00:17:23,596 --> 00:17:25,096
把它替换进来


595
00:17:25,096 --> 00:17:26,886
这样我们下次启动 App 时


596
00:17:26,886 --> 00:17:28,156
就可以使用新的实现


597
00:17:28,156 --> 00:17:28,826
而不是旧版的


598
00:17:28,826 --> 00:17:29,526
实现了


599
00:17:30,736 --> 00:17:32,386
正如我提到的


600
00:17:32,386 --> 00:17:33,846
这个类将建立在


601
00:17:33,846 --> 00:17:35,666
AVSampleBufferAudio Renderer 的基础上


602
00:17:35,896 --> 00:17:36,946
我们也将会用到


603
00:17:37,046 --> 00:17:38,266
AVSampleBufferRender


604
00:17:38,266 --> 00:17:39,016
Synchronizer


605
00:17:39,296 --> 00:17:40,576
这些


606
00:17:40,576 --> 00:17:41,786
David 已经和你们介绍过了


607
00:17:42,376 --> 00:17:43,616
我只想重申一下


608
00:17:43,616 --> 00:17:45,766
David 刚才所说的


609
00:17:45,766 --> 00:17:46,796
AVPlayer 拥有我接下来即将


610
00:17:46,796 --> 00:17:48,176
展示的所有优点


611
00:17:48,176 --> 00:17:49,626
而在你这边只需要


612
00:17:49,626 --> 00:17:50,486
做很少的工作就可以了


613
00:17:50,486 --> 00:17:51,536
所以如果你已经在使用 AVPlayer


614
00:17:51,536 --> 00:17:53,026
或者你认为你可以


615
00:17:53,026 --> 00:17:54,926
用它


616
00:17:54,926 --> 00:17:55,416
我们推荐你这么做


617
00:17:55,596 --> 00:17:57,036
至于其余的人我将


618
00:17:57,036 --> 00:17:58,176
向你展示如何使用


619
00:17:58,176 --> 00:17:58,786
这些新的类别


620
00:18:00,166 --> 00:18:03,716
所以一旦我得到了我的状态


621
00:18:03,716 --> 00:18:05,236
我将使用 addRenderer 的方法


622
00:18:05,776 --> 00:18:06,816
将 AudioRenderer 和


623
00:18:06,816 --> 00:18:08,476
RenderSynchronizer 进行连接


624
00:18:08,476 --> 00:18:10,066
而且我会在


625
00:18:10,066 --> 00:18:11,046
创建了


626
00:18:11,086 --> 00:18:12,516
SampleBufferAudioPlayer 后


627
00:18:12,516 --> 00:18:12,936
立即这样做


628
00:18:13,416 --> 00:18:15,796
然后我们需要与渲染器


629
00:18:15,796 --> 00:18:17,206
进行互动


630
00:18:17,206 --> 00:18:18,396
调出


631
00:18:18,396 --> 00:18:20,486
requestMediaDataWhenReady


632
00:18:20,486 --> 00:18:20,786
方法


633
00:18:20,786 --> 00:18:22,496
它所能做的就是


634
00:18:22,496 --> 00:18:24,236
它将调用我 App 的闭包函数


635
00:18:24,236 --> 00:18:26,766
以便我可以给


636
00:18:26,766 --> 00:18:28,206
AudioRenderer 提供更多的


637
00:18:28,206 --> 00:18:29,756
音频数据


638
00:18:29,756 --> 00:18:30,826
只要 AudioRenderer 认为它需要


639
00:18:30,826 --> 00:18:31,656
接收更多的数据


640
00:18:32,396 --> 00:18:35,296
只要它一有需要


641
00:18:35,296 --> 00:18:37,116
就会调用 App 的闭包函数


642
00:18:37,116 --> 00:18:39,116
保证始终拥有足够的音频数据


643
00:18:40,796 --> 00:18:43,146
在闭包函数内


644
00:18:43,146 --> 00:18:44,666
我将使它循环


645
00:18:44,986 --> 00:18:46,476
我将继续追加更多的数据


646
00:18:46,476 --> 00:18:47,566
只要


647
00:18:47,566 --> 00:18:49,426
AudioRenderer 准备好


648
00:18:49,426 --> 00:18:50,166
接收更多的媒体数据


649
00:18:51,256 --> 00:18:52,886
在循环中第一件事就是


650
00:18:52,886 --> 00:18:55,156
就是获取下一段


651
00:18:55,156 --> 00:18:57,196
音频数据并将它打包成


652
00:18:57,196 --> 00:18:58,716
CMSampleBuffer


653
00:18:59,366 --> 00:19:01,726
这里的这个方法只是


654
00:19:01,826 --> 00:19:04,116
我的这个 App 自己的


655
00:19:04,116 --> 00:19:05,726
抓取后一部分音频数据的


656
00:19:05,726 --> 00:19:06,366
逻辑


657
00:19:06,776 --> 00:19:07,746
你的 App 可以有


658
00:19:07,746 --> 00:19:09,216
你自己的逻辑


659
00:19:09,216 --> 00:19:10,596
可以是从网络上抓取数据


660
00:19:10,596 --> 00:19:11,876
或从光盘上解码


661
00:19:11,876 --> 00:19:13,526
如果你想看我这个版本的更多细节


662
00:19:13,526 --> 00:19:15,426
还是老样子


663
00:19:15,426 --> 00:19:16,376
去网站上的样本代码查看


664
00:19:17,156 --> 00:19:19,056
这里我有这个设置


665
00:19:19,056 --> 00:19:20,796
可以返回一个可选的 CMSampleBuffer


666
00:19:20,796 --> 00:19:22,716
这样一来我可以用一个 0 返回值


667
00:19:22,716 --> 00:19:24,376
来标记出


668
00:19:24,376 --> 00:19:26,926
已经达到了数据的最末端


669
00:19:27,106 --> 00:19:28,976
一旦我得到了样本缓冲


670
00:19:28,976 --> 00:19:30,966
就可以使用 enqueuer 的方法


671
00:19:30,966 --> 00:19:32,046
让它排入


672
00:19:32,046 --> 00:19:32,896
AudioRenderer


673
00:19:32,896 --> 00:19:35,026
它所要做的就是


674
00:19:35,026 --> 00:19:37,146
将音频数据交给


675
00:19:37,146 --> 00:19:38,456
解析器


676
00:19:38,456 --> 00:19:39,406
以便在合适的时间


677
00:19:39,406 --> 00:19:40,216
进行播放


678
00:19:41,286 --> 00:19:43,286
正如刚才提过的


679
00:19:43,566 --> 00:19:44,976
我用一个 0 样本缓冲值


680
00:19:44,976 --> 00:19:46,016
去标记出后面没有任何数据了


681
00:19:46,486 --> 00:19:47,776
当出现这种情况时


682
00:19:47,776 --> 00:19:48,716
我需要明确地告诉


683
00:19:48,716 --> 00:19:50,556
AudioRenderer 停止索要


684
00:19:50,556 --> 00:19:51,416
更多的媒体数据


685
00:19:52,006 --> 00:19:53,406
如果我不这么做并且退出


686
00:19:53,406 --> 00:19:55,376
app的闭包函数


687
00:19:55,376 --> 00:19:57,046
那么 AudioRenderer 就会


688
00:19:57,046 --> 00:19:58,896
在再次准备好接收数据时


689
00:19:58,896 --> 00:20:00,736
立刻触发 App 的闭包函数


690
00:20:00,736 --> 00:20:01,616
但我已经没有更多数据提供给它


691
00:20:01,616 --> 00:20:02,686
我当然不希望


692
00:20:02,686 --> 00:20:03,036
它这么做


693
00:20:03,106 --> 00:20:04,356
所以我需要叫它停止


694
00:20:06,046 --> 00:20:07,796
这里的这个函数基本上


695
00:20:07,796 --> 00:20:09,406
就是你和 AudioRenderer


696
00:20:09,406 --> 00:20:10,896
的全部互动了


697
00:20:10,896 --> 00:20:12,316
这是对于一个简单的使用案例来说


698
00:20:13,476 --> 00:20:14,376
现在我们需要和


699
00:20:14,376 --> 00:20:15,146
RenderSynchronizer


700
00:20:15,146 --> 00:20:16,166
一起来做点事情


701
00:20:16,706 --> 00:20:19,116
这里有一个 play 方法


702
00:20:19,116 --> 00:20:21,066
实际上就是将 RenderSynchronizer


703
00:20:21,066 --> 00:20:22,546
的 rate 设为 1


704
00:20:22,546 --> 00:20:23,906
它就会开始播放


705
00:20:23,906 --> 00:20:25,776
我有一些准备工作要做


706
00:20:25,776 --> 00:20:26,836
我们不需要关注


707
00:20:26,836 --> 00:20:27,956
细节是怎么做的


708
00:20:27,956 --> 00:20:29,576
只需要知道它最后会


709
00:20:29,576 --> 00:20:30,826
引发 enqueueing 方法


710
00:20:30,826 --> 00:20:32,036
你大概能明白


711
00:20:32,036 --> 00:20:32,896
事情是如何一步步进行到这里的了


712
00:20:33,376 --> 00:20:35,096
我还有一些 UI 要更新


713
00:20:35,096 --> 00:20:36,636
在我每次播放或暂停的时候


714
00:20:36,636 --> 00:20:38,326
所以这个方法会


715
00:20:38,326 --> 00:20:39,886
被派到主要的队列


716
00:20:39,886 --> 00:20:41,336
以便让 UI 及时


717
00:20:41,336 --> 00:20:41,586
更新


718
00:20:42,106 --> 00:20:44,566
同样的 我还有一个暂停方法


719
00:20:44,566 --> 00:20:45,736
唯一的区别就是


720
00:20:45,736 --> 00:20:47,376
它将 renderSynchronizer 的


721
00:20:47,376 --> 00:20:49,376
rate 设为 0


722
00:20:50,356 --> 00:20:52,796
那么现在你已经看到了


723
00:20:52,796 --> 00:20:53,546
我们和 AVFoundation


724
00:20:53,546 --> 00:20:54,846
进行的所有互动


725
00:20:55,076 --> 00:20:56,396
我还需要再补充


726
00:20:56,396 --> 00:20:57,576
一点代码


727
00:20:57,576 --> 00:20:59,326
这样才能确保我的 App 顺利运行


728
00:20:59,326 --> 00:21:00,836
我们不用仔细读它是什么


729
00:21:00,836 --> 00:21:02,236
只要加上


730
00:21:02,236 --> 00:21:02,846
就行了


731
00:21:03,556 --> 00:21:05,586
然后我们就完成了


732
00:21:05,586 --> 00:21:06,166
对 App 的重建改造


733
00:21:06,166 --> 00:21:09,036
好像发生了一些


734
00:21:10,356 --> 00:21:11,666
编辑错误


735
00:21:12,296 --> 00:21:14,846
我现在要做的是


736
00:21:15,696 --> 00:21:18,266
找出我哪里做错了


737
00:21:31,666 --> 00:21:32,886
我们可以移走这个


738
00:21:32,966 --> 00:21:37,476
啊 我想我知道


739
00:21:37,476 --> 00:21:38,156
哪里出问题了


740
00:21:52,256 --> 00:21:55,436
把它拖到这里然后


741
00:21:55,546 --> 00:21:58,606
回到这里我们再试一次


742
00:21:58,606 --> 00:22:04,156
好的 我们已经


743
00:22:04,156 --> 00:22:04,426
建好了


744
00:22:04,896 --> 00:22:06,186
现在我们要重启


745
00:22:06,186 --> 00:22:06,486
App


746
00:22:07,156 --> 00:22:08,446
回到我们的并排


747
00:22:08,446 --> 00:22:09,386
视窗


748
00:22:09,386 --> 00:22:13,006
当 App 完成启动后


749
00:22:13,046 --> 00:22:14,806
我就要


750
00:22:14,806 --> 00:22:16,906
重新开始音乐的播放


751
00:22:18,716 --> 00:22:19,536
开始吧


752
00:22:19,726 --> 00:22:23,916
一旦音乐开始播放


753
00:22:23,916 --> 00:22:25,646
现在我们是使用 AirPlay 2


754
00:22:25,646 --> 00:22:28,156
从手机投射到苹果电视上


755
00:22:28,156 --> 00:22:29,296
进行音乐播放


756
00:22:29,946 --> 00:22:31,266
我要再现一遍


757
00:22:31,266 --> 00:22:33,656
刚才的情景


758
00:22:34,066 --> 00:22:34,956
再次用到那个口袋


759
00:22:35,606 --> 00:22:37,636
让我们拿起手机


760
00:22:39,636 --> 00:22:41,086
把它放进口袋里


761
00:22:41,086 --> 00:22:42,606
再一次我拿着手机出去


762
00:22:42,706 --> 00:22:44,676
走出了 Wi-Fi


763
00:22:44,676 --> 00:22:45,226
的覆盖区


764
00:22:46,426 --> 00:22:47,766
我来封严


765
00:22:47,766 --> 00:22:48,106
袋子封口


766
00:22:49,036 --> 00:22:50,476
正如你所看到的


767
00:22:50,476 --> 00:22:51,976
在第一次的演示中


768
00:22:51,976 --> 00:22:53,846
音乐几乎是立刻中断了


769
00:22:53,846 --> 00:22:55,696
但对于这次使用的 AirPlay 2


770
00:22:55,696 --> 00:22:57,146
音乐是一直在播放


771
00:22:57,146 --> 00:22:58,466
尽管遭到了一些


772
00:22:58,466 --> 00:22:59,036
轻微的 Wi-Fi 干扰


773
00:22:59,546 --> 00:23:00,796
这就是 AirPlay 2


774
00:23:00,796 --> 00:23:02,816
组合上 AVSampleBufferAudio


775
00:23:02,816 --> 00:23:03,146
Renderer 产生的魔力


776
00:23:03,516 --> 00:23:04,956
非常感谢


777
00:23:04,956 --> 00:23:05,256
现在把现场交还给 David


778
00:23:07,071 --> 00:23:09,071
鼓掌


779
00:23:09,126 --> 00:23:09,806
>>  感谢 Adam


780
00:23:10,396 --> 00:23:12,136
我们已经带着大家观看了


781
00:23:12,136 --> 00:23:13,606
创建一个简单 App 的步骤


782
00:23:13,606 --> 00:23:14,576
我们用到了 AVSampleBufferAudio


783
00:23:14,576 --> 00:23:16,216
Renderer 以及


784
00:23:16,216 --> 00:23:17,106
AVSampleBufferRender


785
00:23:17,106 --> 00:23:19,336
Synchronizer


786
00:23:19,336 --> 00:23:20,986
下面来看看更多


787
00:23:20,986 --> 00:23:22,406
更复杂的播放场景


788
00:23:22,406 --> 00:23:24,106
你在使用这些 API 时


789
00:23:24,106 --> 00:23:24,416
也许会需要用到


790
00:23:24,696 --> 00:23:27,366
我们在这一段落


791
00:23:27,366 --> 00:23:29,456
要讲到的是


792
00:23:29,456 --> 00:23:30,446
AVSampleBufferAudio Renderer


793
00:23:30,726 --> 00:23:32,356
的音频缓冲级别


794
00:23:32,356 --> 00:23:34,026
我们将谈到如何执行一个 seek


795
00:23:34,026 --> 00:23:36,146
如何执行播放队列


796
00:23:36,146 --> 00:23:38,106
AVSampleBufferAudio Renderer


797
00:23:38,106 --> 00:23:39,926
所支持的


798
00:23:39,926 --> 00:23:41,476
部分音频格式


799
00:23:41,766 --> 00:23:42,806
最后我们要扯远一些


800
00:23:42,806 --> 00:23:44,446
谈一谈视频同步


801
00:23:44,446 --> 00:23:45,486
的问题


802
00:23:47,736 --> 00:23:49,416
那么让我们来进入下一个部分


803
00:23:49,416 --> 00:23:51,496
先来说说


804
00:23:51,496 --> 00:23:52,276
AVSampleBufferAudio Renderer


805
00:23:52,276 --> 00:23:53,566
的音频缓冲级别


806
00:23:54,546 --> 00:23:55,696
我指的是什么呢


807
00:23:55,696 --> 00:23:57,616
我指的是


808
00:23:57,616 --> 00:23:59,836
App 中 AVSampleBufferAudio


809
00:23:59,836 --> 00:24:01,176
Renderer


810
00:24:01,176 --> 00:24:03,496
对于音频数据的需求量


811
00:24:03,706 --> 00:24:05,886
会依据现有的路由而变化


812
00:24:07,156 --> 00:24:08,506
让我们通过图表


813
00:24:08,506 --> 00:24:09,016
来了解一下


814
00:24:09,526 --> 00:24:10,886
这里我画出了一条媒体时间线


815
00:24:10,886 --> 00:24:12,606
在这儿放下一个


816
00:24:12,606 --> 00:24:13,036
播放头


817
00:24:14,456 --> 00:24:15,286
当你在本地播放时


818
00:24:15,286 --> 00:24:17,496
AudioRenderer 只要求


819
00:24:17,496 --> 00:24:18,566
播放头


820
00:24:18,566 --> 00:24:20,076
前几秒的内容


821
00:24:21,186 --> 00:24:23,256
那就是你应该


822
00:24:23,256 --> 00:24:24,866
排入队列的部分


823
00:24:24,866 --> 00:24:25,856
按它所要求的


824
00:24:27,146 --> 00:24:29,066
随着你继续播放


825
00:24:29,066 --> 00:24:30,036
把播放头的右边几秒


826
00:24:30,036 --> 00:24:31,606
排入队列即可


827
00:24:32,996 --> 00:24:34,546
但假设用户突然决定


828
00:24:34,546 --> 00:24:36,926
要投射到一个


829
00:24:36,926 --> 00:24:37,326
AirPlay 2 音箱


830
00:24:38,596 --> 00:24:40,246
这种情况发生时


831
00:24:40,246 --> 00:24:42,146
AVSampleBufferAudio Renderer 将


832
00:24:42,146 --> 00:24:43,766
要求播放头右边


833
00:24:43,766 --> 00:24:45,016
几分钟的长度


834
00:24:46,306 --> 00:24:47,746
再次当你按下播放


835
00:24:47,746 --> 00:24:49,276
你需要在播放头右边几分钟


836
00:24:49,276 --> 00:24:50,286
开始工作


837
00:24:51,376 --> 00:24:53,126
这里的关键是


838
00:24:53,126 --> 00:24:54,866
AVSampleBufferAudio Renderer


839
00:24:54,866 --> 00:24:56,516
需要多少数据量


840
00:24:56,936 --> 00:24:58,586
取决于音频当下的传输路径


841
00:24:58,586 --> 00:24:59,486
是在哪里


842
00:24:59,486 --> 00:25:01,716
如果音频是本地传输


843
00:25:01,716 --> 00:25:03,126
这一过程可能只需要几秒


844
00:25:03,126 --> 00:25:04,716
通过蓝牙 需要几秒钟


845
00:25:04,716 --> 00:25:06,236
通过 AirPlay 1 代的音箱也是几秒钟


846
00:25:07,236 --> 00:25:08,806
但如果用户是将音频内容


847
00:25:08,806 --> 00:25:10,846
传输到支持 AirPlay 2 的音箱上


848
00:25:10,846 --> 00:25:13,616
那么 AudioRenderer 将会


849
00:25:13,616 --> 00:25:14,556
非常“饥饿”


850
00:25:14,556 --> 00:25:15,686
对于音频数据


851
00:25:15,686 --> 00:25:16,816
它可能会需要几分钟的时间


852
00:25:18,096 --> 00:25:19,326
重点是你的 App


853
00:25:19,326 --> 00:25:20,376
必须有所准备


854
00:25:20,376 --> 00:25:21,016
来处理这些变化


855
00:25:21,516 --> 00:25:25,146
好的 接下来让我们谈谈


856
00:25:25,146 --> 00:25:25,516
seek


857
00:25:26,856 --> 00:25:27,936
什么是 seek


858
00:25:28,136 --> 00:25:29,856
Seek 简单来说就是


859
00:25:29,856 --> 00:25:31,816
手动改变


860
00:25:31,816 --> 00:25:32,796
播放头的位置


861
00:25:33,876 --> 00:25:35,046
我们再来画出


862
00:25:35,046 --> 00:25:36,526
刚才看到的


863
00:25:36,526 --> 00:25:37,366
媒体时间线


864
00:25:38,176 --> 00:25:40,006
放入播放头


865
00:25:40,006 --> 00:25:42,276
我们来进行本地播放


866
00:25:42,876 --> 00:25:44,036
或者说是标准的播放场景


867
00:25:44,716 --> 00:25:46,836
用户点击播放


868
00:25:46,836 --> 00:25:48,286
然后当音频开始播放后


869
00:25:48,286 --> 00:25:49,496
用户决定


870
00:25:49,496 --> 00:25:51,206
我想要在这一曲目中


871
00:25:51,206 --> 00:25:51,576
向后去 seek


872
00:25:51,576 --> 00:25:52,956
于是他们抬起播放头


873
00:25:52,956 --> 00:25:54,206
并向右拖动


874
00:25:55,076 --> 00:25:56,506
他们要求 seek


875
00:25:57,046 --> 00:25:59,496
AVSampleBufferAudio Renderer


876
00:25:59,496 --> 00:26:00,806
是如何处理这种情况的


877
00:26:01,366 --> 00:26:02,626
其实是非常容易的


878
00:26:03,696 --> 00:26:04,496
你要做的第一件事


879
00:26:04,496 --> 00:26:05,296
就是要


880
00:26:05,296 --> 00:26:05,716
停止


881
00:26:05,836 --> 00:26:07,606
停止 AVSampleBufferRender


882
00:26:07,606 --> 00:26:08,986
Synchronizer 的播放


883
00:26:08,986 --> 00:26:10,326
并停止


884
00:26:10,326 --> 00:26:12,416
往 AVSampleBufferAudioRenderer 里


885
00:26:12,416 --> 00:26:13,376
继续排列


886
00:26:13,376 --> 00:26:13,666
媒体数据


887
00:26:14,176 --> 00:26:17,226
下一步你要在


888
00:26:17,226 --> 00:26:18,356
SampleBufferAudioRenderer


889
00:26:18,356 --> 00:26:19,956
发布一个 flush


890
00:26:19,956 --> 00:26:21,556
它将清除已经排列起来的


891
00:26:21,556 --> 00:26:22,566
所有媒体数据


892
00:26:23,106 --> 00:26:25,716
那时你就可以


893
00:26:25,716 --> 00:26:27,646
在任意媒体时间上


894
00:26:27,646 --> 00:26:30,456
开始重新排列音频数据


895
00:26:30,456 --> 00:26:32,786
也就是在 seek 所在的时间点


896
00:26:32,786 --> 00:26:33,256
开始重新排列


897
00:26:33,796 --> 00:26:36,216
当你在 seek 所在的时间点


898
00:26:36,216 --> 00:26:38,246
排列了媒体数据后


899
00:26:38,246 --> 00:26:39,846
再次开始播放


900
00:26:39,846 --> 00:26:40,146
好了


901
00:26:40,216 --> 00:26:43,876
这就是 seek


902
00:26:45,096 --> 00:26:46,586
现在我已经向你展示了


903
00:26:46,586 --> 00:26:47,926
Seek 是如何工作的


904
00:26:47,926 --> 00:26:49,046
让我们来看看如何在代码中执行它


905
00:26:49,046 --> 00:26:51,266
我们要在 Adam 的 App 中


906
00:26:51,806 --> 00:26:52,686
使用一个叫做 seektoMediaTime


907
00:26:52,686 --> 00:26:53,516
的方法


908
00:26:54,626 --> 00:26:55,846
具体怎么做呢


909
00:26:56,116 --> 00:26:56,926
非常简单


910
00:26:57,336 --> 00:26:58,536
第一件事就是


911
00:26:58,536 --> 00:26:59,936
我们要告诉


912
00:26:59,936 --> 00:27:01,246
RenderSynchronizer 停止播放


913
00:27:01,246 --> 00:27:02,756
做法是


914
00:27:02,756 --> 00:27:03,156
把 rate 设为 0


915
00:27:03,966 --> 00:27:04,766
然后告诉 AudioRenderer


916
00:27:04,766 --> 00:27:06,286
停止索要


917
00:27:06,286 --> 00:27:07,456
媒体数据


918
00:27:08,406 --> 00:27:10,056
然后我们将清理


919
00:27:10,056 --> 00:27:11,556
AudioRenderer


920
00:27:11,556 --> 00:27:12,666
以便清空队列中的


921
00:27:12,666 --> 00:27:13,106
旧的音频数据


922
00:27:14,436 --> 00:27:15,516
然后我们在调用一些 App


923
00:27:15,516 --> 00:27:17,706
特别代码


924
00:27:17,706 --> 00:27:20,016
它将告诉你的样本生成代码


925
00:27:20,016 --> 00:27:21,346
要准备的下一段样本


926
00:27:21,346 --> 00:27:23,056
位置在


927
00:27:23,056 --> 00:27:23,906
seek 处


928
00:27:24,346 --> 00:27:26,066
记住你的 App 有责任


929
00:27:26,066 --> 00:27:27,556
在使用这个 API 时


930
00:27:28,176 --> 00:27:30,706
去提供音频数据


931
00:27:30,706 --> 00:27:32,226
所以你要告诉它


932
00:27:32,226 --> 00:27:33,596
下一段音频样本应该


933
00:27:33,596 --> 00:27:33,916
从哪里生成


934
00:27:34,446 --> 00:27:37,046
之后


935
00:27:37,046 --> 00:27:38,516
你可以重新设置


936
00:27:38,516 --> 00:27:40,006
AudioRenderer 的闭包函数


937
00:27:40,006 --> 00:27:41,296
让它去重新调用要求更多数据


938
00:27:41,986 --> 00:27:43,426
你可以把 RenderSynchronizer


939
00:27:43,426 --> 00:27:44,246
rate 设为 1


940
00:27:45,556 --> 00:27:46,216
比较简单


941
00:27:46,526 --> 00:27:47,136
那就是 seek


942
00:27:47,586 --> 00:27:49,976
让我们来看看


943
00:27:49,976 --> 00:27:50,946
更有趣的内容吧


944
00:27:50,946 --> 00:27:51,406
播放队列


945
00:27:51,406 --> 00:27:53,576
什么是播放队列


946
00:27:53,576 --> 00:27:54,716
我们这里有一张


947
00:27:54,716 --> 00:27:55,286
Adam 的 App 截图


948
00:27:55,856 --> 00:27:57,516
播放队列很简单


949
00:27:57,516 --> 00:27:59,686
就是你将一系列的条目


950
00:27:59,686 --> 00:28:00,086
进行排序


951
00:28:00,086 --> 00:28:01,396
我点击播放后


952
00:28:01,396 --> 00:28:02,176
它们就会按顺序逐一播放


953
00:28:02,616 --> 00:28:05,756
我们来看看这个播放队列


954
00:28:05,756 --> 00:28:06,976
把它在媒体时间线上


955
00:28:07,046 --> 00:28:08,616
列出来


956
00:28:08,616 --> 00:28:09,896
能看到条目 1 的后面是条目 2


957
00:28:09,896 --> 00:28:11,876
然后是条目 3


958
00:28:13,156 --> 00:28:14,956
这就是一个非常常见的样子


959
00:28:14,956 --> 00:28:16,896
这些条目平铺


960
00:28:16,896 --> 00:28:17,826
在时间线上


961
00:28:18,606 --> 00:28:19,886
但如果我们仔细研究


962
00:28:19,886 --> 00:28:22,026
尤其是对每一个条目的


963
00:28:22,026 --> 00:28:23,196
时间线进行仔细观察


964
00:28:23,196 --> 00:28:24,076
我们就会发现有些地方


965
00:28:24,076 --> 00:28:24,806
是存在细小差别的


966
00:28:25,116 --> 00:28:26,416
让我们假设


967
00:28:26,416 --> 00:28:27,996
每个条目的长度


968
00:28:27,996 --> 00:28:28,346
是 100 秒


969
00:28:29,426 --> 00:28:30,886
这就意味着每个条目


970
00:28:30,886 --> 00:28:33,936
都是从


971
00:28:33,936 --> 00:28:34,336
0 到 100


972
00:28:34,896 --> 00:28:38,636
当然 AudioRenderer


973
00:28:38,636 --> 00:28:39,986
是不知道这些


974
00:28:39,986 --> 00:28:40,996
条目的信息的


975
00:28:41,266 --> 00:28:42,536
AudioRenderer 所知道的


976
00:28:42,536 --> 00:28:43,816
只是一条连续的媒体时间线


977
00:28:45,146 --> 00:28:46,606
所以当你让音频数据排队


978
00:28:46,836 --> 00:28:48,596
进入 AVSampleBufferAudio


979
00:28:48,596 --> 00:28:51,096
Renderer


980
00:28:51,736 --> 00:28:53,946
你就需要将条目的自然时间线


981
00:28:54,056 --> 00:28:55,816
变成一条 AVSampleBufferAudio


982
00:28:55,816 --> 00:28:57,086
Renderer


983
00:28:57,086 --> 00:28:57,336
连续的时间线


984
00:28:57,896 --> 00:29:00,396
让我们再看看


985
00:29:00,396 --> 00:29:01,976
刚才看过的


986
00:29:01,976 --> 00:29:02,746
这个排队列的动画


987
00:29:03,356 --> 00:29:05,076
这里我正在播放本地音频


988
00:29:05,076 --> 00:29:06,226
我刚刚把


989
00:29:06,226 --> 00:29:07,266
播放头右边的几秒


990
00:29:07,496 --> 00:29:09,406
排入队列


991
00:29:09,406 --> 00:29:10,966
正如你所看到的 我会把这些条目


992
00:29:10,966 --> 00:29:11,486
按顺序排列进来


993
00:29:12,346 --> 00:29:13,606
如果用户是要投射到


994
00:29:13,606 --> 00:29:14,806
AirPlay 2 音箱 那我们就要


995
00:29:14,806 --> 00:29:15,676
在播放头右边较远的地方开始工作


996
00:29:15,676 --> 00:29:16,846
但还是一个道理


997
00:29:16,846 --> 00:29:18,156
你只要把播放头右边的部分


998
00:29:18,156 --> 00:29:20,176
多放一些到


999
00:29:21,136 --> 00:29:21,336
队列里就行


1000
00:29:21,366 --> 00:29:21,836
好了


1001
00:29:22,646 --> 00:29:24,426
这就是播放队列的


1002
00:29:24,426 --> 00:29:24,896
基本概念


1003
00:29:24,896 --> 00:29:25,566
接下来就


1004
00:29:25,566 --> 00:29:26,536
更有趣了


1005
00:29:26,776 --> 00:29:27,316
编辑队列


1006
00:29:28,566 --> 00:29:29,566
在这个假设的情景中


1007
00:29:29,566 --> 00:29:32,266
让我们假设用户决定


1008
00:29:32,266 --> 00:29:33,206
他们不想听


1009
00:29:33,206 --> 00:29:34,226
条目 2 了


1010
00:29:34,466 --> 00:29:35,746
他们就把它移出队列


1011
00:29:35,746 --> 00:29:37,916
于是条目 3 和条目 4


1012
00:29:37,916 --> 00:29:41,486
往前移替代了它的位置


1013
00:29:41,606 --> 00:29:43,836
这种情况


1014
00:29:43,836 --> 00:29:44,326
没什么复杂的


1015
00:29:44,536 --> 00:29:46,806
用户会预期条目 1 播放完


1016
00:29:46,806 --> 00:29:48,516
然后是条目 3


1017
00:29:48,516 --> 00:29:49,296
再是条目 4


1018
00:29:49,826 --> 00:29:52,166
不过这是一个相当简单的


1019
00:29:52,166 --> 00:29:53,186
编辑播放队列的例子


1020
00:29:53,186 --> 00:29:56,416
在播放前


1021
00:29:56,756 --> 00:29:58,106
我就对队列进行了编辑


1022
00:30:00,086 --> 00:30:01,516
但我们在使用


1023
00:30:01,516 --> 00:30:03,776
AVSampleBufferAudio Renderer 时


1024
00:30:03,776 --> 00:30:04,206
经常要提前载入


1025
00:30:04,206 --> 00:30:05,586
播放头右边很长一段的内容


1026
00:30:06,176 --> 00:30:07,376
你很可能遇到这样的情况


1027
00:30:07,376 --> 00:30:10,146
当用户


1028
00:30:10,146 --> 00:30:11,456
开始


1029
00:30:11,456 --> 00:30:12,346
播放


1030
00:30:12,946 --> 00:30:15,436
你此刻还在播放条目 1


1031
00:30:15,436 --> 00:30:17,646
但条目 2 的媒体数据


1032
00:30:17,646 --> 00:30:18,886
已经进入队列载入


1033
00:30:19,426 --> 00:30:22,136
这时用户决定


1034
00:30:22,136 --> 00:30:22,996
不想听


1035
00:30:22,996 --> 00:30:23,276
条目 2 了


1036
00:30:23,276 --> 00:30:25,966
于是用户期待着


1037
00:30:25,966 --> 00:30:28,496
条目 2 消失


1038
00:30:28,496 --> 00:30:29,046
条目 3 和 4 替换上来


1039
00:30:29,616 --> 00:30:33,266
再一次


1040
00:30:33,266 --> 00:30:35,356
用户期待着


1041
00:30:35,356 --> 00:30:36,226
在条目 1 之后


1042
00:30:36,226 --> 00:30:37,886
条目 3  会开始


1043
00:30:37,886 --> 00:30:38,166
播放


1044
00:30:39,576 --> 00:30:40,576
如果我们此时什么都不做


1045
00:30:40,576 --> 00:30:41,646
此时条目 2 的音频数据


1046
00:30:41,646 --> 00:30:43,586
已经排列在


1047
00:30:43,586 --> 00:30:45,146
AudioRenderer 中


1048
00:30:45,146 --> 00:30:46,196
接下来我们就会听到条目 2 播放


1049
00:30:46,286 --> 00:30:48,916
然后声音突然中断


1050
00:30:48,916 --> 00:30:50,356
因为我们在


1051
00:30:50,356 --> 00:30:50,906
AudioRenderer 中存入了错误的数据


1052
00:30:51,506 --> 00:30:54,046
那我们该怎么做呢


1053
00:30:54,636 --> 00:30:55,706
其实也容易处理


1054
00:30:55,706 --> 00:30:57,336
因为在 Source Time 里


1055
00:30:57,336 --> 00:30:58,666
有一个指令


1056
00:30:58,666 --> 00:30:59,506
叫做 Flush


1057
00:31:00,746 --> 00:31:01,866
这个指令的功能


1058
00:31:01,866 --> 00:31:03,686
它的意思


1059
00:31:03,686 --> 00:31:05,436
就是在我指定的时间点


1060
00:31:05,436 --> 00:31:07,046
我希望你


1061
00:31:07,046 --> 00:31:08,776
清除时间线上这个时间点以后的


1062
00:31:08,776 --> 00:31:11,056
所有媒体数据


1063
00:31:11,256 --> 00:31:12,596
我在这里调用


1064
00:31:12,596 --> 00:31:15,226
Flush from Source Time


1065
00:31:15,226 --> 00:31:18,146
指定连续时间线上的


1066
00:31:18,176 --> 00:31:20,016
这个时间点


1067
00:31:20,016 --> 00:31:22,176
连续的时间线为


1068
00:31:22,176 --> 00:31:22,756
条目1和下一个条目提供完美过渡


1069
00:31:23,326 --> 00:31:24,296
于是我就调用这个指令


1070
00:31:24,296 --> 00:31:25,056
它就清空了所有的媒体数据


1071
00:31:25,056 --> 00:31:27,876
它要做的下一件事


1072
00:31:27,876 --> 00:31:29,286
就是把指针重新放到


1073
00:31:29,286 --> 00:31:31,206
指定时间点后正在队列中的样本缓冲


1074
00:31:31,356 --> 00:31:33,226
之后我就可以


1075
00:31:33,226 --> 00:31:35,186
把条目 3 的 媒体数据排入队列了


1076
00:31:36,416 --> 00:31:37,436
当然


1077
00:31:37,436 --> 00:31:39,166
随着音频播放 问题迎刃而解


1078
00:31:40,116 --> 00:31:42,076
值得注意的一点是


1079
00:31:42,076 --> 00:31:44,006
在刚才的动画演示中


1080
00:31:44,006 --> 00:31:46,796
看起来好像播放被暂停了


1081
00:31:46,796 --> 00:31:48,486
但实际上


1082
00:31:48,486 --> 00:31:49,856
你可以在音频播放的过程中


1083
00:31:50,026 --> 00:31:51,716
执行这个指令


1084
00:31:51,716 --> 00:31:53,166
这个操作完全可以


1085
00:31:53,166 --> 00:31:53,736
对你的用户


1086
00:31:55,936 --> 00:31:56,826
公开


1087
00:31:57,396 --> 00:31:58,876
接下来我们说说执行


1088
00:31:58,876 --> 00:32:00,336
这个 flush from source time 指令


1089
00:32:00,336 --> 00:32:01,036
所需要的步骤


1090
00:32:01,036 --> 00:32:02,356
大致来说有三步


1091
00:32:02,356 --> 00:32:04,026
第一步 停止在渲染器中


1092
00:32:04,026 --> 00:32:04,846
列入音频数据


1093
00:32:05,166 --> 00:32:06,566
注意 我说的不是停止播放


1094
00:32:06,706 --> 00:32:07,726
因为你不需要


1095
00:32:07,726 --> 00:32:08,386
这么做


1096
00:32:09,226 --> 00:32:09,876
然后你就发布


1097
00:32:09,876 --> 00:32:12,196
Flush from SourceTime 的指令


1098
00:32:12,196 --> 00:32:12,766
在你发布


1099
00:32:12,766 --> 00:32:14,856
Flush from SourceTime 之后


1100
00:32:14,856 --> 00:32:15,896
flush from sourcetime 是一个


1101
00:32:15,896 --> 00:32:17,886
非同步的操作


1102
00:32:18,066 --> 00:32:19,396
在这里你可以传递一个闭包函数


1103
00:32:19,986 --> 00:32:20,756
你需要等待回调函数


1104
00:32:20,756 --> 00:32:21,586
的发出


1105
00:32:22,126 --> 00:32:25,946
这里还有几个小的技巧


1106
00:32:25,946 --> 00:32:26,716
虽说它是一个


1107
00:32:26,716 --> 00:32:28,046
相对简单的操作


1108
00:32:28,046 --> 00:32:29,526
第一点就是  flush 有可能会


1109
00:32:29,526 --> 00:32:29,866
失败


1110
00:32:30,746 --> 00:32:31,736
为什么会失败


1111
00:32:32,236 --> 00:32:34,096
假如你指定的时间点


1112
00:32:34,096 --> 00:32:35,536
距离播放头太接近


1113
00:32:35,536 --> 00:32:36,896
或者是放在了播放头的左边


1114
00:32:37,706 --> 00:32:39,426
在这些情况下


1115
00:32:39,426 --> 00:32:40,486
我们可能无法从


1116
00:32:40,486 --> 00:32:41,686
音频硬件中获得


1117
00:32:41,686 --> 00:32:42,076
音频的数据了


1118
00:32:43,336 --> 00:32:46,066
在这样的情况下


1119
00:32:46,066 --> 00:32:47,866
与其让你陷入未知的状态


1120
00:32:47,866 --> 00:32:49,806
可能会播放过期数据


1121
00:32:49,806 --> 00:32:51,366
我们宁愿选择让这个


1122
00:32:51,366 --> 00:32:52,986
操作失败


1123
00:32:52,986 --> 00:32:54,946
看起来像是这个指令


1124
00:32:54,946 --> 00:32:57,536
从没被发布过一样


1125
00:32:57,716 --> 00:32:59,326
第二点小技巧是


1126
00:32:59,326 --> 00:33:00,536
正如凡事都有利有弊


1127
00:33:00,536 --> 00:33:01,886
你需要等待


1128
00:33:01,886 --> 00:33:02,826
回调函数


1129
00:33:03,296 --> 00:33:05,146
这个回调函数


1130
00:33:05,146 --> 00:33:06,346
将告诉你


1131
00:33:06,346 --> 00:33:07,246
Flush 是否失败了


1132
00:33:07,246 --> 00:33:10,326
如果它失败了


1133
00:33:10,326 --> 00:33:11,346
你需要采取相应的措施


1134
00:33:12,056 --> 00:33:12,986
让我们来看看相应的代码


1135
00:33:12,986 --> 00:33:14,566
还是刚才的样本 App


1136
00:33:14,566 --> 00:33:17,036
通过引用一个方法


1137
00:33:17,036 --> 00:33:18,246
通过执行一个方法


1138
00:33:18,246 --> 00:33:18,906
叫做


1139
00:33:19,396 --> 00:33:21,726
FlushfromSourceTime


1140
00:33:21,726 --> 00:33:22,506
来执行 FlushfromSourceTime


1141
00:33:23,656 --> 00:33:26,836
再一次 在这个方法中


1142
00:33:26,966 --> 00:33:28,156
你需要做的头件事


1143
00:33:28,156 --> 00:33:28,906
就是通知


1144
00:33:28,906 --> 00:33:30,366
AudioRenderer 停止


1145
00:33:30,366 --> 00:33:30,866
索要媒体数据


1146
00:33:31,746 --> 00:33:33,046
之后你可能想去调用


1147
00:33:33,046 --> 00:33:34,886
一些 App 特定的逻辑


1148
00:33:34,886 --> 00:33:36,296
以确保没有


1149
00:33:36,296 --> 00:33:37,956
更多的媒体数据


1150
00:33:37,956 --> 00:33:38,776
被排入队列


1151
00:33:38,776 --> 00:33:40,646
这点至关重要


1152
00:33:40,886 --> 00:33:42,056
因为这是一个非同步的操作


1153
00:33:42,056 --> 00:33:43,316
所以它本身就


1154
00:33:43,316 --> 00:33:43,736
有一定风险


1155
00:33:44,166 --> 00:33:44,986
所以我们希望能确保


1156
00:33:44,986 --> 00:33:46,136
在 FlushfromSourceTime 的运行过程中


1157
00:33:46,136 --> 00:33:47,646
你没有将更多的音频数据


1158
00:33:47,646 --> 00:33:49,276
排入队列中


1159
00:33:49,766 --> 00:33:52,466
当你确信


1160
00:33:52,466 --> 00:33:53,586
你没有将


1161
00:33:53,586 --> 00:33:54,826
更多的音频数据排入 AudioRenderer


1162
00:33:55,196 --> 00:33:56,426
这时就可以执行


1163
00:33:56,426 --> 00:33:57,416
FlushfromSourceTime 了


1164
00:33:57,876 --> 00:33:59,296
再次 你可以传递一个闭包函数


1165
00:33:59,296 --> 00:34:00,506
因为这是一个非同步的


1166
00:34:00,666 --> 00:34:01,306
操作


1167
00:34:01,416 --> 00:34:02,846
这个闭包函数会告诉你


1168
00:34:02,846 --> 00:34:04,846
对于闭包函数的调用


1169
00:34:04,846 --> 00:34:05,616
是否


1170
00:34:05,616 --> 00:34:06,296
Flush 是否


1171
00:34:06,296 --> 00:34:06,886
成功


1172
00:34:07,606 --> 00:34:09,196
如果像我这里演示的这样 成功了


1173
00:34:09,196 --> 00:34:11,485
你之后要做的第一件事就是


1174
00:34:11,485 --> 00:34:12,545
再一次


1175
00:34:12,545 --> 00:34:13,505
告诉你的负责样本生成的 App


1176
00:34:13,505 --> 00:34:15,266
然后 App 的样本生成代码


1177
00:34:15,545 --> 00:34:17,856
就开始


1178
00:34:17,985 --> 00:34:19,815
从指定的时间点处


1179
00:34:19,815 --> 00:34:20,036
准备样本


1180
00:34:20,735 --> 00:34:22,036
然后你可以重新调用你的


1181
00:34:22,036 --> 00:34:23,545
回调函数


1182
00:34:23,545 --> 00:34:24,755
并再次开始排入队列


1183
00:34:25,696 --> 00:34:27,585
当然 这里的 flush 有可能会失败


1184
00:34:27,996 --> 00:34:29,456
这时你想如何处理


1185
00:34:29,456 --> 00:34:30,886
就真的全靠 App


1186
00:34:30,886 --> 00:34:32,056
明确的逻辑来决定了


1187
00:34:32,786 --> 00:34:33,926
或许你想要进入


1188
00:34:33,926 --> 00:34:34,735
下一个播放曲目


1189
00:34:34,735 --> 00:34:35,946
或许你想要执行一个彻底的 flush


1190
00:34:35,946 --> 00:34:37,656
清除播放的小差错


1191
00:34:37,656 --> 00:34:38,216
怎么做全凭你决定


1192
00:34:38,786 --> 00:34:43,286
以上就是播放队列和


1193
00:34:43,286 --> 00:34:44,085
Flush from Source Time


1194
00:34:44,856 --> 00:34:47,676
下面我们来聊聊


1195
00:34:47,676 --> 00:34:48,646
AVSampleBufferAudio Renderer


1196
00:34:48,646 --> 00:34:49,746
支持的音频格式


1197
00:34:51,656 --> 00:34:53,156
那么  AVSampleBufferAudio Renderer


1198
00:34:53,156 --> 00:34:55,085
都支持哪些


1199
00:34:55,085 --> 00:34:55,516
音频格式呢


1200
00:34:55,516 --> 00:34:57,886
好消息是 基本上所有


1201
00:34:57,886 --> 00:34:59,376
平台支持的音频格式


1202
00:34:59,376 --> 00:35:00,596
AVSampleBufferAudio Renderer 也都


1203
00:35:00,596 --> 00:35:01,816
支持


1204
00:35:01,906 --> 00:35:04,526
这就包括了 LPCM AAC


1205
00:35:04,556 --> 00:35:07,376
mp3 Apple Lossless 


1206
00:35:07,376 --> 00:35:09,506
包括各种采样率


1207
00:35:10,556 --> 00:35:10,756
各种位深


1208
00:35:10,866 --> 00:35:13,126
而且 不同格式的音频


1209
00:35:13,126 --> 00:35:13,886
有时也可以排入同一队列


1210
00:35:14,466 --> 00:35:17,346
如果条目 1 是一个采样率为 44.1 的 AAC 音频


1211
00:35:17,346 --> 00:35:19,556
你也可以在它后面排入 48 k 的 MP 3 音频


1212
00:35:19,556 --> 00:35:23,376
以及 16 位 48 khz 的


1213
00:35:23,786 --> 00:35:24,976
Apple Lossless 音频


1214
00:35:25,156 --> 00:35:26,836
你可以让这几种音频的数据


1215
00:35:26,836 --> 00:35:28,036
一个接一个地入列


1216
00:35:28,036 --> 00:35:29,196
我们会替你解决


1217
00:35:29,196 --> 00:35:30,406
格式转换的问题


1218
00:35:31,466 --> 00:35:33,236
这就介绍完了


1219
00:35:33,236 --> 00:35:33,616
支持的格式


1220
00:35:33,826 --> 00:35:34,866
下面来说说


1221
00:35:34,866 --> 00:35:35,386
最佳格式


1222
00:35:35,926 --> 00:35:38,706
既然我们能播放任何格式


1223
00:35:38,706 --> 00:35:39,716
你有什么都可以给我们


1224
00:35:39,766 --> 00:35:41,176
你有 LPCM 丢给我们


1225
00:35:41,176 --> 00:35:42,166
经过编码的 丢给我们


1226
00:35:42,656 --> 00:35:44,276
预先提醒一下


1227
00:35:44,276 --> 00:35:46,186
在其他条件都一样的前提下


1228
00:35:46,186 --> 00:35:48,846
如果你需要在经过编码的音频


1229
00:35:48,846 --> 00:35:50,126
和 PCM 中间做出选择


1230
00:35:50,126 --> 00:35:51,576
我们会偏向经过编码的音频


1231
00:35:51,576 --> 00:35:53,196
但不要添加特别的逻辑进去


1232
00:35:53,286 --> 00:35:54,126
有什么直接丢给我们就好


1233
00:35:55,416 --> 00:35:56,476
此外 我们还更喜欢


1234
00:35:56,476 --> 00:35:58,336
交叉容错通道格式以及


1235
00:35:58,336 --> 00:35:59,536
包含 1 到 2 秒的音频缓冲的


1236
00:35:59,536 --> 00:36:00,366
CMSampleBuffer 格式


1237
00:36:00,366 --> 00:36:03,946
好的 现在我想把话题稍微扯远一点


1238
00:36:03,946 --> 00:36:05,326
来谈谈


1239
00:36:05,326 --> 00:36:06,356
视频同步的问题


1240
00:36:07,656 --> 00:36:08,606
你可能会奇怪


1241
00:36:08,606 --> 00:36:09,996
为什么我们要在一个主讲


1242
00:36:09,996 --> 00:36:11,776
AirPlay 音频的演讲中


1243
00:36:11,776 --> 00:36:12,226
谈到视频


1244
00:36:13,196 --> 00:36:15,196
原因就是


1245
00:36:15,196 --> 00:36:16,466
今天我们介绍的类别


1246
00:36:16,466 --> 00:36:18,706
它们不仅适用于 AirPlay  2 


1247
00:36:18,886 --> 00:36:19,796
它们也是


1248
00:36:19,796 --> 00:36:21,346
非常好的播放 API


1249
00:36:21,346 --> 00:36:22,056
即使对于一般的使用来说


1250
00:36:22,666 --> 00:36:24,036
你也许想用它们来


1251
00:36:24,036 --> 00:36:24,656
播放视频


1252
00:36:25,226 --> 00:36:26,836
再说一遍 如果你能使用


1253
00:36:26,836 --> 00:36:28,186
AVPlayer  请选择它


1254
00:36:28,186 --> 00:36:29,946
但如果你无法使用 AVPlayer


1255
00:36:29,946 --> 00:36:31,636
你又想播放视频


1256
00:36:32,236 --> 00:36:33,066
那么看好了


1257
00:36:33,416 --> 00:36:36,496
让我们回到


1258
00:36:36,496 --> 00:36:37,686
刚才在演讲中展示过的


1259
00:36:37,686 --> 00:36:38,786
框架图中


1260
00:36:38,936 --> 00:36:40,506
这里有客户端 App


1261
00:36:40,506 --> 00:36:41,206
AudioRenderer 以及


1262
00:36:41,206 --> 00:36:41,766
Synchronizer


1263
00:36:42,586 --> 00:36:43,826
如果我把它们移出去


1264
00:36:43,826 --> 00:36:45,206
就有空间放入


1265
00:36:45,206 --> 00:36:47,426
一个新的渲染器类别


1266
00:36:47,426 --> 00:36:48,396
我打算加入一个


1267
00:36:48,396 --> 00:36:49,626
AVSampleBufferDisplayLayer


1268
00:36:50,556 --> 00:36:51,766
如果你们对


1269
00:36:51,766 --> 00:36:52,366
AVSampleBufferDisplayLayer


1270
00:36:52,366 --> 00:36:54,596
不熟悉的话


1271
00:36:54,596 --> 00:36:56,176
它是一个类似于新的


1272
00:36:56,176 --> 00:36:57,546
AVSampleBufferAudio Renderer 的类别


1273
00:36:57,756 --> 00:36:58,956
唯一差别是它


1274
00:36:58,956 --> 00:36:59,716
更面向视频内容


1275
00:37:00,136 --> 00:37:01,026
它已经推出了一段时间


1276
00:37:01,026 --> 00:37:01,546
你能在开发者网站上


1277
00:37:01,546 --> 00:37:04,256
找到相关的文件和


1278
00:37:04,256 --> 00:37:05,196
样本代码


1279
00:37:06,166 --> 00:37:09,136
但这次发布中的新鲜内容是


1280
00:37:09,136 --> 00:37:10,266
你可以用 RenderSynchronizer


1281
00:37:10,266 --> 00:37:12,576
去控制它的


1282
00:37:12,576 --> 00:37:13,446
时间线


1283
00:37:13,726 --> 00:37:14,636
你可以把它加到


1284
00:37:14,636 --> 00:37:15,886
RenderSynchronizer 里


1285
00:37:15,886 --> 00:37:16,896
就像你把 AudioRenderer 加入到


1286
00:37:16,896 --> 00:37:17,626
RenderSynchronizer 里


1287
00:37:18,046 --> 00:37:19,906
这真的很酷


1288
00:37:19,956 --> 00:37:21,636
因为这样一来你就能


1289
00:37:21,636 --> 00:37:23,736
把音频数据加到 AudioRenderer 里


1290
00:37:24,166 --> 00:37:27,366
把视频数据加到视频渲染器中


1291
00:37:27,366 --> 00:37:30,326
设同步器的 rate 为 1


1292
00:37:30,326 --> 00:37:32,726
因为


1293
00:37:32,726 --> 00:37:33,466
它们使用的是同一个时间线


1294
00:37:33,466 --> 00:37:34,916
出来后是同步的


1295
00:37:34,916 --> 00:37:35,126
结果


1296
00:37:35,676 --> 00:37:37,086
有几句提醒


1297
00:37:37,306 --> 00:37:39,026
视频不会被 AirPlay 投射


1298
00:37:39,466 --> 00:37:40,476
而且当你在使用长形时


1299
00:37:40,476 --> 00:37:42,036
你只能把一个


1300
00:37:42,036 --> 00:37:43,286
AudioRenderer 加进


1301
00:37:43,286 --> 00:37:44,126
RenderSynchronizer


1302
00:37:44,716 --> 00:37:46,386
不过我觉得你已经能够


1303
00:37:46,386 --> 00:37:48,556
感受到这个架构中的


1304
00:37:48,556 --> 00:37:49,946
力量以及灵活性


1305
00:37:50,176 --> 00:37:51,246
我相信你们一定会


1306
00:37:51,246 --> 00:37:52,676
摸索出一些非常酷的使用实例


1307
00:37:52,676 --> 00:37:54,336
和应用


1308
00:37:54,336 --> 00:37:56,546
我们很期待你们的探索结果


1309
00:37:57,676 --> 00:37:58,106
好的


1310
00:37:58,106 --> 00:37:59,336
最后我们来谈谈


1311
00:37:59,336 --> 00:38:00,716
AirPlay 2 的可用性


1312
00:38:02,086 --> 00:38:04,406
我很高兴地说


1313
00:38:04,406 --> 00:38:06,706
我今天和大家讨论的这些 API


1314
00:38:06,706 --> 00:38:08,456
以及改进后的缓冲系统


1315
00:38:08,456 --> 00:38:10,976
都在你们今天能够进入的


1316
00:38:10,976 --> 00:38:12,206
测试版中可以使用


1317
00:38:13,486 --> 00:38:16,566
如果你把开发人员面板上的


1318
00:38:16,566 --> 00:38:18,286
AirPlay 2 切换键


1319
00:38:18,476 --> 00:38:19,276
点开


1320
00:38:19,716 --> 00:38:21,166
之后就能使用一个升级后的苹果电视


1321
00:38:21,166 --> 00:38:22,766
它可以作为 AirPlay 2 的接收端


1322
00:38:22,766 --> 00:38:24,686
发送给它


1323
00:38:26,016 --> 00:38:27,376
在即将发布的测试版中


1324
00:38:27,376 --> 00:38:28,766
我们将实现多房间音频控制功能


1325
00:38:29,586 --> 00:38:30,606
最后一点 这些将在


1326
00:38:30,606 --> 00:38:31,896
即将发布的版本中


1327
00:38:31,896 --> 00:38:32,726
供用户使用


1328
00:38:33,616 --> 00:38:34,476
我们来总结一下


1329
00:38:34,476 --> 00:38:36,006
今天讲了很多内容


1330
00:38:36,396 --> 00:38:38,456
AirPlay 2 在音频方面


1331
00:38:38,456 --> 00:38:39,456
有很多新的功能


1332
00:38:41,056 --> 00:38:42,566
使用长形音频的应用


1333
00:38:42,566 --> 00:38:44,566
按照我今天概括的步骤去做


1334
00:38:44,566 --> 00:38:45,366
就可以实现这些功能


1335
00:38:46,336 --> 00:38:48,206
嵌入 AirPlay 2


1336
00:38:48,206 --> 00:38:49,356
可以从你们手中的测试版


1337
00:38:49,356 --> 00:38:51,286
开始尝试


1338
00:38:51,536 --> 00:38:54,096
还有一些信息


1339
00:38:54,096 --> 00:38:55,556
这个网站将提供


1340
00:38:55,556 --> 00:38:56,496
我们今天的演讲内容


1341
00:38:56,496 --> 00:38:57,516
样本代码也即将


1342
00:38:57,516 --> 00:38:58,756
提供给大家


1343
00:38:59,346 --> 00:39:02,016
还有我们刚才提到的


1344
00:39:02,016 --> 00:39:02,806
几个介绍会


1345
00:39:02,806 --> 00:39:03,926
包括 What's New in Audio 介绍会


1346
00:39:03,926 --> 00:39:04,996
它更加深入地


1347
00:39:04,996 --> 00:39:06,356
讨论了长形音频


1348
00:39:06,356 --> 00:39:07,676
同时介绍了


1349
00:39:07,676 --> 00:39:08,176
MusicKit


1350
00:39:08,616 --> 00:39:09,516
推荐大家去


1351
00:39:09,516 --> 00:39:09,726
看看


1352
00:39:10,026 --> 00:39:11,086
非常感谢


1353
00:39:11,086 --> 00:39:11,856
希望大家这星期余下的时间


1354
00:39:11,856 --> 00:39:12,116
也过得愉快

