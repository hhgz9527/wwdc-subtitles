1
00:00:28,596 --> 00:00:29,576
>>大家下午好


2
00:00:30,076 --> 00:00:32,006
欢迎参加“Metal 2 


3
00:00:32,006 --> 00:00:32,946
的计算功能”会议


4
00:00:33,886 --> 00:00:35,296
我叫 Anna Tikhonova


5
00:00:35,296 --> 00:00:36,686
是 GPU 软件团队的


6
00:00:36,686 --> 00:00:37,976
工程师 现在就开始吧


7
00:00:42,156 --> 00:00:44,046
Metal 2 回波系统的功能


8
00:00:44,046 --> 00:00:45,836
比 Metal API 和语言要


9
00:00:45,836 --> 00:00:46,356
多得多


10
00:00:46,796 --> 00:00:48,946
我们还拥有 GPU 工具
 
00:00:48,946 --> 00:00:50,336
以及 MetalKit 和


11
00:00:50,336 --> 00:00:51,586
Metal Performance Shader 框架


12
00:00:53,006 --> 00:00:54,146
你可能会认为 Metal 是


13
00:00:54,496 --> 00:00:56,376
开发高端游戏和图像


14
00:00:56,376 --> 00:00:57,566
的优秀技术


15
00:00:58,396 --> 00:00:59,616
但它同时也用于


16
00:00:59,616 --> 00:01:00,506
计算处理


17
00:01:01,626 --> 00:01:02,806
事实上 Metal 在计算方面


18
00:01:02,806 --> 00:01:04,616
非常强大和灵活
 
00:01:04,616 --> 00:01:06,526
以至于 Metal 


19
00:01:06,526 --> 00:01:08,196
Performance Shader 框架


20
00:01:08,196 --> 00:01:09,326
完全建立在


21
00:01:09,406 --> 00:01:09,756
计算之上


22
00:01:11,026 --> 00:01:12,486
在本次会议中 我们将介绍


23
00:01:12,486 --> 00:01:14,076
Metal Performance Shader 框架


24
00:01:14,076 --> 00:01:15,176
的新功能


25
00:01:17,956 --> 00:01:19,596
我们在 2015 年推出了


26
00:01:19,596 --> 00:01:21,026
Metal Performers Shader 框架


27
00:01:21,026 --> 00:01:22,756
简称 MPS


28
00:01:23,486 --> 00:01:24,546
之前的会议视频


29
00:01:24,546 --> 00:01:25,916
可以在我们的开发者


30
00:01:25,916 --> 00:01:28,906
网站上找到


31
00:01:29,266 --> 00:01:30,686
MPS 利用 GPU 的


32
00:01:30,686 --> 00:01:33,446
计算功能为 GPU 提供


33
00:01:33,446 --> 00:01:33,816
加速图元


34
00:01:34,286 --> 00:01:35,886
用于图像处理


35
00:01:35,926 --> 00:01:37,416
线性代数和机器学习


36
00:01:39,146 --> 00:01:40,416
这个框架针对 iOS 


37
00:01:40,416 --> 00:01:42,336
进行了优化 我们很高兴地宣布


38
00:01:42,336 --> 00:01:44,096
今年 MPS 也将在


39
00:01:44,096 --> 00:01:44,836
Mac 上应用


40
00:01:45,516 --> 00:01:49,786
[掌声] 


41
00:01:50,286 --> 00:01:50,716
谢谢


42
00:01:51,926 --> 00:01:53,366
整个功能集都


43
00:01:53,366 --> 00:01:55,616
可以在 iOS 和 macOS 系统中使用


44
00:01:55,616 --> 00:01:58,476
所以我们先来快速地


45
00:01:58,476 --> 00:02:00,336
看一下图像处理支持的


46
00:02:00,336 --> 00:02:00,686
新进展


47
00:02:02,046 --> 00:02:03,866
这里列出了


48
00:02:03,866 --> 00:02:05,576
在 iOS 10 中可以使用的


49
00:02:05,696 --> 00:02:07,486
所有图像处理图元


50
00:02:08,106 --> 00:02:09,675
有 Convolution Gaussian Blur


51
00:02:09,675 --> 00:02:11,586
Lanczos Resampling


52
00:02:11,586 --> 00:02:12,196
就举几个例子


53
00:02:13,126 --> 00:02:14,726
这些现在都可以在 macOS 系统中


54
00:02:14,726 --> 00:02:14,996
使用了


55
00:02:16,146 --> 00:02:17,656
今年我们为大家带来


56
00:02:17,656 --> 00:02:18,926
四种新的图像处理


57
00:02:18,926 --> 00:02:19,336
图元


58
00:02:20,466 --> 00:02:21,816
Image Keypoint


59
00:02:22,206 --> 00:02:24,316
图元可以用于 通常用于


60
00:02:24,316 --> 00:02:26,256
计算机视觉算法 例如


61
00:02:26,256 --> 00:02:28,596
稳像和


62
00:02:28,596 --> 00:02:29,926
双线性缩放


63
00:02:29,926 --> 00:02:31,726
图像统计


64
00:02:31,726 --> 00:02:33,246
元素级算术运算符
 
00:02:33,326 --> 00:02:34,826
通常用于图像


65
00:02:34,826 --> 00:02:35,156
预处理


66
00:02:35,466 --> 00:02:36,386
例如在机器


67
00:02:36,386 --> 00:02:36,656
学习中


68
00:02:37,556 --> 00:02:38,926
算术递增滤色镜也


69
00:02:38,926 --> 00:02:40,446
支持广播操作


70
00:02:41,256 --> 00:02:42,716
例如 允许


71
00:02:42,716 --> 00:02:44,766
添加 2D 图像或 1D 图像


72
00:02:46,176 --> 00:02:48,406
这就是我们对图像处理


73
00:02:48,406 --> 00:02:49,606
新进展的快速介绍


74
00:02:49,986 --> 00:02:51,286
现在我们来谈谈新的


75
00:02:51,286 --> 00:02:52,386
线性代数运算


76
00:02:54,286 --> 00:02:55,686
没有矩阵乘法 
                                                                                                              
00:02:55,686 --> 00:02:57,436
矩阵向量


77
00:02:57,436 --> 00:02:59,736
乘法 三角


78
00:03:00,076 --> 00:03:01,866
矩阵因式分解和


79
00:03:01,866 --> 00:03:02,306
线性求解器的支持


80
00:03:05,356 --> 00:03:06,376
为了支持线性代数


81
00:03:06,376 --> 00:03:09,256
运算 我们现在有了很多


82
00:03:09,256 --> 00:03:10,356
新的数据表示


83
00:03:11,066 --> 00:03:13,076
首先是 MPSVector 对象


84
00:03:13,076 --> 00:03:15,186
它可以将 Metal 


85
00:03:15,186 --> 00:03:16,496
缓冲区中的数据解释为


86
00:03:16,496 --> 00:03:17,416
一维数组


87
00:03:19,106 --> 00:03:21,506
然后是 MPSMatrix 对象
 
00:03:22,076 --> 00:03:23,276
它可以将 Metal 缓冲区中的


88
00:03:23,276 --> 00:03:24,886
数据解释为矩形


89
00:03:24,886 --> 00:03:25,156
数组


90
00:03:25,886 --> 00:03:27,656
而 MPS 矩阵以行序为


91
00:03:27,656 --> 00:03:28,176
主序


92
00:03:28,956 --> 00:03:30,166
你可以将


93
00:03:30,166 --> 00:03:32,956
MPSVector 和 MPSMatrice 都看作是


94
00:03:33,456 --> 00:03:34,736
用户数据缓冲区周围的


95
00:03:34,736 --> 00:03:35,096
封装


96
00:03:37,436 --> 00:03:39,296
而且我们也支持 MPSMatrix 的


97
00:03:39,296 --> 00:03:40,926
临时变化


98
00:03:42,296 --> 00:03:45,196
MPS 图像 临时图像


99
00:03:45,196 --> 00:03:47,056
和 MPS 临时矩阵从


100
00:03:47,056 --> 00:03:48,666
与命令缓冲区相关联的


101
00:03:48,906 --> 00:03:49,956
Metal 堆中分配


102
00:03:49,956 --> 00:03:50,216
出来


103
00:03:50,766 --> 00:03:51,856
之所以称为临时的
 
00:03:52,226 --> 00:03:54,066
是因为它们的寿命


104
00:03:54,216 --> 00:03:55,996
受限于命令缓冲区的


105
00:03:55,996 --> 00:03:56,516
使用寿命


106
00:03:57,546 --> 00:03:58,866
我们建议


107
00:03:58,896 --> 00:04:00,176
在大多数中间存储器中


108
00:04:00,636 --> 00:04:02,526
使用临时映像和


109
00:04:03,006 --> 00:04:03,206
矩阵


110
00:04:04,316 --> 00:04:07,416
MPSVector 和 MPSMatrix 都


111
00:04:07,576 --> 00:04:09,116
支持多种输入类型


112
00:04:09,646 --> 00:04:11,596
我们支持单精度


113
00:04:11,596 --> 00:04:14,236
半精度输入类型以及


114
00:04:14,236 --> 00:04:15,266
浮点输入类型


115
00:04:15,756 --> 00:04:17,696
还有 16 位和 8 位带符号


116
00:04:17,986 --> 00:04:19,125
整数输入类型


117
00:04:21,016 --> 00:04:22,136
现在我们来看看怎样


118
00:04:22,136 --> 00:04:24,446
创建大小为 N 的


119
00:04:24,536 --> 00:04:24,886
MPS 向量


120
00:04:24,886 --> 00:04:26,856
如果你还没有


121
00:04:26,856 --> 00:04:28,346
Metal 缓冲区 那就需要先


122
00:04:28,346 --> 00:04:28,606
创建一个


123
00:04:29,666 --> 00:04:30,666
然后再为你的向量


124
00:04:30,666 --> 00:04:31,686
创建一个描述符


125
00:04:32,526 --> 00:04:34,546
请注意 你需要指定


126
00:04:34,726 --> 00:04:36,086
向量的长度


127
00:04:36,666 --> 00:04:38,146
因为向量可以


128
00:04:38,146 --> 00:04:39,946
由原来 Metal 缓冲区的


129
00:04:39,946 --> 00:04:40,926
一部分形成


130
00:04:41,716 --> 00:04:43,236
并且可以在使用该向量


131
00:04:43,236 --> 00:04:44,556
的内核中设置其他相关的


132
00:04:44,556 --> 00:04:45,016
偏移量


133
00:04:45,996 --> 00:04:47,406
最后使用


134
00:04:47,466 --> 00:04:49,586
描述符从缓冲区


135
00:04:49,586 --> 00:04:50,906
创建一个向量


136
00:04:52,966 --> 00:04:53,976
现在我们来看看


137
00:04:53,976 --> 00:04:56,256
如何创建一个 M 行


138
00:04:56,326 --> 00:04:57,906
N 列的 MPS 矩阵


139
00:04:59,516 --> 00:05:00,906
这和创建 MPS 向量


140
00:05:00,906 --> 00:05:02,916
的方式非常类似 


141
00:05:02,916 --> 00:05:04,006
但有几点


142
00:05:04,006 --> 00:05:04,726
需要注意


143
00:05:06,176 --> 00:05:08,256
我们提供了一个方便的 API


144
00:05:08,256 --> 00:05:09,606
你可以用它来查找


145
00:05:09,606 --> 00:05:11,966
每个行值的推荐字节数
 
00:05:12,556 --> 00:05:13,756
用于调整 Metal 缓冲区的大小


146
00:05:14,666 --> 00:05:15,716
如果你选择使用 API


147
00:05:15,796 --> 00:05:17,246
那么这就是


148
00:05:17,246 --> 00:05:18,816
使用这个推荐值创建 Metal 缓冲区


149
00:05:18,816 --> 00:05:19,596
的方法


150
00:05:20,596 --> 00:05:22,106
并且这个 API 是完全


151
00:05:22,106 --> 00:05:24,416
可以选择性使用的 但我们推荐使用


152
00:05:24,416 --> 00:05:25,136
因为它的性能更好


153
00:05:25,986 --> 00:05:27,156
其余的就简单了


154
00:05:28,256 --> 00:05:29,356
你先为矩阵创建一个


155
00:05:29,356 --> 00:05:30,886
描述符 然后创建一个


156
00:05:30,886 --> 00:05:32,346
带有描述符的矩阵


157
00:05:34,936 --> 00:05:36,506
既然刚刚我们讲过了


158
00:05:36,506 --> 00:05:37,806
数据表示 那么现在


159
00:05:37,806 --> 00:05:39,046
我们来看一下图元


160
00:05:39,896 --> 00:05:41,176
对于矩阵-矩阵和


161
00:05:41,176 --> 00:05:43,136
矩阵-向量的乘法 我们的


162
00:05:43,136 --> 00:05:44,586
API 以


163
00:05:44,586 --> 00:05:46,036
标准的 BLAS GEMM 和 GEMV


164
00:05:46,036 --> 00:05:46,766
界面为模型


165
00:05:47,646 --> 00:05:48,846
对于三角矩阵


166
00:05:48,846 --> 00:05:50,196
矢量化和线性


167
00:05:50,196 --> 00:05:52,216
求解器 我们的 API 以


168
00:05:52,216 --> 00:05:53,246
标准的 LAPACK 


169
00:05:53,246 --> 00:05:54,916
分解和求解


170
00:05:54,916 --> 00:05:55,486
界面为模型


171
00:05:55,846 --> 00:05:57,036
所以如果你熟悉这些


172
00:05:57,036 --> 00:05:59,106
界面 那对我们的 API
 
00:05:59,106 --> 00:06:00,526
你也不会陌生


173
00:06:02,576 --> 00:06:04,216
现在我们来看一个


174
00:06:04,216 --> 00:06:05,546
非常简单的代码示例


175
00:06:05,836 --> 00:06:07,536
我们要做矩阵的


176
00:06:07,536 --> 00:06:08,996
乘法和计算


177
00:06:08,996 --> 00:06:10,426
C = A 乘以 B


178
00:06:10,426 --> 00:06:12,716
所以首先我们需要创建


179
00:06:12,716 --> 00:06:14,476
矩阵 A B 和 C


180
00:06:14,706 --> 00:06:15,646
但我知道大家已经知道怎么


181
00:06:15,646 --> 00:06:16,786
操作了 因为在前一张幻灯片里我已经


182
00:06:16,836 --> 00:06:18,306
讲过 所以我们继续往下看


183
00:06:19,336 --> 00:06:21,116
现在我们要在 GPU 上


184
00:06:21,116 --> 00:06:22,596
运行矩阵的乘法


185
00:06:23,886 --> 00:06:25,386
首先像往常一样进行 Metal 


186
00:06:25,466 --> 00:06:27,446
设置来获取设备


187
00:06:27,446 --> 00:06:29,076
命令队列和命令


188
00:06:29,076 --> 00:06:29,356
缓冲区


189
00:06:29,356 --> 00:06:31,766
然后我们需要创建


190
00:06:31,846 --> 00:06:33,186
矩阵乘法内核


191
00:06:33,766 --> 00:06:35,196
注意 你这里需要


192
00:06:35,196 --> 00:06:36,296
指定结果的大小


193
00:06:36,826 --> 00:06:38,216
因为这个内核可以


194
00:06:38,216 --> 00:06:39,896
在矩阵的子区域上


195
00:06:39,896 --> 00:06:40,436
运行


196
00:06:41,066 --> 00:06:45,576
然后将这个内核编码


197
00:06:45,656 --> 00:06:47,056
到 GPU 上 并让它开始


198
00:06:47,056 --> 00:06:47,476
工作


199
00:06:47,476 --> 00:06:51,036
我们已经在


200
00:06:51,036 --> 00:06:52,346
开发者网站上提供了


201
00:06:52,586 --> 00:06:53,906
矩阵乘法的示例代码


202
00:06:53,906 --> 00:06:56,096
以及三角矩阵


203
00:06:56,096 --> 00:06:57,896
向量化的代码


204
00:06:58,206 --> 00:06:59,556
求解线性方程组的示例代码


205
00:06:59,556 --> 00:07:00,986
很快也要发布


206
00:07:03,026 --> 00:07:05,526
这就是我们关于


207
00:07:05,756 --> 00:07:07,026
线性代数运算的内容


208
00:07:07,386 --> 00:07:08,996
现在我们来看下一个


209
00:07:08,996 --> 00:07:10,756
主题 也就是


210
00:07:10,756 --> 00:07:12,156
在 GPU 上加速机器


211
00:07:12,156 --> 00:07:12,636
学习图元


212
00:07:14,116 --> 00:07:16,246
在今年的 WWDC


213
00:07:16,246 --> 00:07:17,906
大会上有很多关于


214
00:07:17,906 --> 00:07:19,156
机器学习的会议


215
00:07:19,456 --> 00:07:20,346
而我们就是机器学习


216
00:07:20,346 --> 00:07:21,416
团体的一部分


217
00:07:22,306 --> 00:07:23,586
这一页展示了


218
00:07:23,586 --> 00:07:24,206
整体的架构


219
00:07:25,086 --> 00:07:26,606
作为一名应用程序开发人员
 
00:07:26,816 --> 00:07:27,876
你可以通过使用


220
00:07:27,876 --> 00:07:28,816
高级域


221
00:07:28,816 --> 00:07:30,956
特定框架
 
00:07:30,996 --> 00:07:32,856
比如分区框架


222
00:07:32,856 --> 00:07:34,456
和依赖于 Core ML 框架的


223
00:07:34,456 --> 00:07:35,566
自然语言处理框架


224
00:07:35,616 --> 00:07:37,496
为应用程序添加


225
00:07:37,496 --> 00:07:38,366
机器学习功能


226
00:07:39,216 --> 00:07:40,376
Core ML 框架由


227
00:07:40,446 --> 00:07:42,316
CPU 上的


228
00:07:42,316 --> 00:07:44,076
加速框架 BNNS 


229
00:07:44,076 --> 00:07:44,606
原语 


230
00:07:45,066 --> 00:07:46,176
以及 GPU 上的


231
00:07:47,066 --> 00:07:49,046
机器学习和


232
00:07:49,046 --> 00:07:51,946
MPS 框架驱动构成


233
00:07:51,946 --> 00:07:52,706
但是如果你正在编写一个


234
00:07:52,706 --> 00:07:54,556
使用 Metal 的应用程序
 
00:07:54,906 --> 00:07:56,046
那么你可以直接使用


235
00:07:56,046 --> 00:07:58,176
MPS框架 我稍后


236
00:07:58,176 --> 00:07:59,386
将在这个会议中向你展示如何操作


237
00:08:01,666 --> 00:08:02,676
让我们从正在讲的


238
00:08:02,736 --> 00:08:03,486
这个部分开始


239
00:08:04,246 --> 00:08:05,116
什么是深度学习
 
00:08:05,366 --> 00:08:06,236
什么是机器学习
 
00:08:07,686 --> 00:08:08,766
想象一下这是你


240
00:08:08,766 --> 00:08:11,436
当你看到一个图像


241
00:08:11,436 --> 00:08:13,076
你立刻就能知道上面描绘的


242
00:08:13,076 --> 00:08:13,316
是什么


243
00:08:13,416 --> 00:08:13,956
这是一只熊猫


244
00:08:14,936 --> 00:08:16,686
现在想一想你的


245
00:08:16,686 --> 00:08:18,006
iPhone 上所有的图像


246
00:08:18,596 --> 00:08:20,206
或者你家庭相册中的


247
00:08:20,206 --> 00:08:20,996
所有照片


248
00:08:21,606 --> 00:08:22,646
或者互联网上的


249
00:08:22,646 --> 00:08:22,966
所有图像


250
00:08:23,816 --> 00:08:27,096
没有人可以


251
00:08:27,096 --> 00:08:28,816
将这么多的图像分类


252
00:08:29,086 --> 00:08:30,506
但深度学习算法就是


253
00:08:30,506 --> 00:08:32,056
专门为此而


254
00:08:32,056 --> 00:08:32,196
设计的


255
00:08:33,186 --> 00:08:34,416
它们可以用于筛选


256
00:08:34,416 --> 00:08:35,576
大量数据


257
00:08:36,015 --> 00:08:37,866
并回答诸如


258
00:08:37,996 --> 00:08:41,676
图像的内容是什么 等一系列问题


259
00:08:42,236 --> 00:08:43,306
深度学习算法有


260
00:08:43,405 --> 00:08:43,905
两个阶段


261
00:08:44,206 --> 00:08:45,156
训练和推理


262
00:08:45,426 --> 00:08:46,426
让我们先来讲一下


263
00:08:46,426 --> 00:08:46,736
训练


264
00:08:47,946 --> 00:08:49,246
让我们用一个


265
00:08:49,246 --> 00:08:49,676
例子


266
00:08:49,676 --> 00:08:51,326
我们训练一个系统来进行


267
00:08:51,326 --> 00:08:51,716
图像分类


268
00:08:52,586 --> 00:08:53,536
这个系统训练可以


269
00:08:53,536 --> 00:08:56,696
进行图像分类 例如


270
00:08:56,696 --> 00:08:58,066
你想让系统识别


271
00:08:58,126 --> 00:08:58,536
动物


272
00:08:58,966 --> 00:09:00,516
要让它识别猫
 
00:09:00,516 --> 00:09:02,126
那么你就需要为这个系统输入


273
00:09:02,556 --> 00:09:04,196
大量的包含


274
00:09:04,196 --> 00:09:06,126
猫 兔子和


275
00:09:06,126 --> 00:09:07,336
所有其他你希望


276
00:09:07,336 --> 00:09:08,406
系统能识别动物的


277
00:09:08,406 --> 00:09:08,866
标签的图像


278
00:09:10,546 --> 00:09:12,316
而这个训练步骤是


279
00:09:12,316 --> 00:09:13,916
一次性的


280
00:09:13,916 --> 00:09:16,476
它消耗计算能力且劳动


281
00:09:16,566 --> 00:09:16,786
强度大


282
00:09:17,896 --> 00:09:19,076
它通常是离线完成的


283
00:09:19,696 --> 00:09:20,896
但是训练阶段的结果


284
00:09:20,896 --> 00:09:22,336
是下一阶段


285
00:09:23,306 --> 00:09:24,656
也就是推理阶段
 
00:09:24,656 --> 00:09:25,856
所需要的训练参数


286
00:09:26,906 --> 00:09:28,096
这时候可以将一个从未见过的


287
00:09:28,186 --> 00:09:30,156
新图像呈现在


288
00:09:30,156 --> 00:09:31,736
你的系统中
 
00:09:31,736 --> 00:09:33,186
并对其进行分类


289
00:09:33,186 --> 00:09:33,396
这是一个帽子


290
00:09:35,126 --> 00:09:37,016
我们为第二阶段


291
00:09:37,016 --> 00:09:38,306
也就是推理阶段提供视图


292
00:09:38,306 --> 00:09:38,526
加速


293
00:09:39,096 --> 00:09:40,966
具体来说 去年我们


294
00:09:40,966 --> 00:09:42,936
讨论了在 GPU 上


295
00:09:43,056 --> 00:09:44,296
构建卷积神经网络的


296
00:09:44,296 --> 00:09:45,716
构建块 用于


297
00:09:45,716 --> 00:09:46,146
推理


298
00:09:48,466 --> 00:09:50,176
所以在继续介绍


299
00:09:50,176 --> 00:09:51,966
今年推出的


300
00:09:51,966 --> 00:09:52,826
机器学习的新功能


301
00:09:52,856 --> 00:09:53,936
之前 我们将


302
00:09:53,936 --> 00:09:55,136
回顾一下


303
00:09:55,136 --> 00:09:56,886
去年演讲中介绍的


304
00:09:56,886 --> 00:09:58,146
一些核心信息


305
00:09:58,736 --> 00:10:00,416
比如 什么是卷积


306
00:10:00,416 --> 00:10:00,966
神经网络


307
00:10:02,396 --> 00:10:04,326
在这之后 我们才会


308
00:10:04,326 --> 00:10:06,056
谈到今年为


309
00:10:06,106 --> 00:10:06,836
卷积神经网络添加的


310
00:10:06,836 --> 00:10:07,906
新原语


311
00:10:07,966 --> 00:10:09,426
然后我们将


312
00:10:09,426 --> 00:10:11,146
介绍一种新的 易用的


313
00:10:11,516 --> 00:10:12,636
神经网络图像 API


314
00:10:13,166 --> 00:10:14,746
而我们最后一个话题是


315
00:10:14,746 --> 00:10:15,726
循环神经网络


316
00:10:18,606 --> 00:10:20,976
让我们按照刚才的概述开始讲


317
00:10:21,106 --> 00:10:22,066
那么 什么是卷积神经


318
00:10:22,066 --> 00:10:22,366
网络


319
00:10:24,446 --> 00:10:25,576
卷积神经网络


320
00:10:25,576 --> 00:10:27,426
受生物学启发而设计出来


321
00:10:27,426 --> 00:10:28,836
用于近似


322
00:10:28,836 --> 00:10:29,246
视觉皮质


323
00:10:29,796 --> 00:10:31,406
所以让我们想一下


324
00:10:31,406 --> 00:10:33,076
大脑是如何处理视觉输入的


325
00:10:34,256 --> 00:10:35,636
在视觉皮质中


326
00:10:35,736 --> 00:10:37,056
接收信息的第一层


327
00:10:37,056 --> 00:10:39,396
神经元对


328
00:10:39,396 --> 00:10:40,786
特定的边缘和色块很


329
00:10:40,886 --> 00:10:41,196
敏感


330
00:10:42,366 --> 00:10:43,466
而大脑区域进一步的


331
00:10:43,466 --> 00:10:45,966
视觉传递会对 


332
00:10:45,966 --> 00:10:47,596
更复杂的结构做出反应
 
00:10:47,596 --> 00:10:49,366
比如朋友的面孔或者


333
00:10:49,366 --> 00:10:50,166
动物 比如猫


334
00:10:50,996 --> 00:10:53,646
所以类似的 卷积神经网络


335
00:10:53,646 --> 00:10:55,836
是多层次结构


336
00:10:55,836 --> 00:10:58,176
其中高级特征


337
00:10:58,296 --> 00:10:59,836
源于低级


338
00:10:59,836 --> 00:11:00,246
特征


339
00:11:01,156 --> 00:11:02,516
因此你的网络中的前几个


340
00:11:02,516 --> 00:11:04,566
层次会对低级特征


341
00:11:04,566 --> 00:11:06,766
比如边缘和色块做出


342
00:11:06,826 --> 00:11:07,196
响应


343
00:11:07,886 --> 00:11:10,646
而随后的层次


344
00:11:10,766 --> 00:11:12,516
对逐渐复杂的特征


345
00:11:12,616 --> 00:11:14,886
比如面孔 做出响应


346
00:11:16,106 --> 00:11:17,406
我一直在说特征


347
00:11:17,846 --> 00:11:19,556
你可以将特征视为


348
00:11:19,556 --> 00:11:21,176
一个过滤器 可以过滤输入的


349
00:11:21,176 --> 00:11:22,706
数据 就是那个特征


350
00:11:25,316 --> 00:11:26,906
这里列出了我们在


351
00:11:26,976 --> 00:11:28,076
iOS 10 中提供的


352
00:11:28,076 --> 00:11:29,356
所有卷积神经网络原语


353
00:11:29,756 --> 00:11:31,806
在这个概述中我将


354
00:11:31,806 --> 00:11:33,686
只讲核心


355
00:11:34,176 --> 00:11:35,146
卷积层


356
00:11:35,216 --> 00:11:36,426
CNN 的核心


357
00:11:36,546 --> 00:11:36,756
构建块


358
00:11:36,756 --> 00:11:39,046
这些原语的其余部分


359
00:11:39,106 --> 00:11:40,906
在我们的演讲文档中


360
00:11:40,906 --> 00:11:42,266
有很详细的


361
00:11:42,266 --> 00:11:43,076
介绍


362
00:11:43,196 --> 00:11:44,566
Pooling Fully-Connected 和


363
00:11:44,616 --> 00:11:45,156
SoftMax.


364
00:11:45,746 --> 00:11:46,856
你可以找到和这些相关的


365
00:11:46,856 --> 00:11:47,056
信息


366
00:11:48,626 --> 00:11:50,386
所以让我们来谈谈


367
00:11:50,386 --> 00:11:51,186
核心构建块


368
00:11:52,596 --> 00:11:54,216
这个核心卷积层的功能


369
00:11:54,216 --> 00:11:56,196
是识别输入


370
00:11:56,196 --> 00:11:57,766
数据中的特征
 
00:11:57,766 --> 00:11:58,906
它之所以被称为


371
00:11:58,906 --> 00:12:01,076
卷积层是因为


372
00:12:01,126 --> 00:12:02,576
它对输入进行


373
00:12:02,576 --> 00:12:02,846
卷积操作


374
00:12:03,916 --> 00:12:05,246
我们回想一下常规的


375
00:12:05,246 --> 00:12:06,076
卷积如何进行


376
00:12:06,906 --> 00:12:08,146
你有输入


377
00:12:08,186 --> 00:12:09,366
输出和过滤器


378
00:12:10,366 --> 00:12:12,386
使用输入数据来


379
00:12:12,386 --> 00:12:14,506
调用过滤器 你需要将


380
00:12:14,756 --> 00:12:16,626
过滤器中的


381
00:12:16,626 --> 00:12:18,446
每个值与输入数据中的值相乘
 
00:12:18,446 --> 00:12:19,686
并将该信息组合


382
00:12:19,686 --> 00:12:21,106
从而计算出单个输出值


383
00:12:22,046 --> 00:12:23,536
对于其余的输出像素


384
00:12:23,636 --> 00:12:25,166
你也进行同样的操作


385
00:12:27,596 --> 00:12:29,856
而现在卷积层则是


386
00:12:29,856 --> 00:12:31,606
常规卷积的


387
00:12:31,606 --> 00:12:32,226
一般化


388
00:12:32,396 --> 00:12:34,666
它允许你拥有多个


389
00:12:34,666 --> 00:12:35,136
过滤器


390
00:12:35,526 --> 00:12:37,536
所以你可以拥有和输出通道


391
00:12:37,536 --> 00:12:38,916
一样多的过滤器


392
00:12:38,916 --> 00:12:39,816
这种情况下是 16 个


393
00:12:41,666 --> 00:12:43,046
这些过滤器将


394
00:12:43,046 --> 00:12:44,656
过滤具有特定 
                  
00:12:44,656 --> 00:12:46,006
特征的输入数据


395
00:12:47,726 --> 00:12:49,016
现在想象一下你正在


396
00:12:49,016 --> 00:12:50,266
使用 RGB 数据


397
00:12:50,356 --> 00:12:52,186
那么你的输入实际上


398
00:12:52,186 --> 00:12:53,266
有三个通道


399
00:12:54,156 --> 00:12:56,276
鉴于 CNN 的工作原理
 
00:12:56,476 --> 00:12:58,816
这意味着你需要三组过滤器


400
00:12:58,886 --> 00:13:00,156
每组 16 个


401
00:13:00,866 --> 00:13:02,576
每个输入通道一组


402
00:13:03,856 --> 00:13:05,916
然后将这些滤波器


403
00:13:05,916 --> 00:13:07,296
分别应用于


404
00:13:08,486 --> 00:13:09,036
输入数据


405
00:13:09,036 --> 00:13:10,816
然后最后一步将


406
00:13:10,816 --> 00:13:12,386
所有这些信息合并


407
00:13:12,386 --> 00:13:13,796
计算出单个输出像素


408
00:13:15,516 --> 00:13:17,156
这就是我们对


409
00:13:17,156 --> 00:13:18,006
卷积层的概述


410
00:13:18,536 --> 00:13:19,526
现在我们来谈谈


411
00:13:19,576 --> 00:13:20,846
为卷积神经网络


412
00:13:20,846 --> 00:13:22,026
添加的新原语


413
00:13:22,116 --> 00:13:25,176
如你所见 我们添加了


414
00:13:25,176 --> 00:13:25,686
不少原语


415
00:13:27,736 --> 00:13:29,096
但我接下来只讲一下


416
00:13:29,096 --> 00:13:31,476
黄色的部分
 
00:13:31,476 --> 00:13:33,206
其他的比如 L2Norm 


417
00:13:33,256 --> 00:13:34,686
Pooling Resampling
 
00:13:34,686 --> 00:13:36,086
和 Up-sampling 这些都将


418
00:13:36,086 --> 00:13:37,396
在我们的文档中介绍


419
00:13:39,286 --> 00:13:40,986
那让我们来看看对核心


420
00:13:40,986 --> 00:13:42,786
卷积层进行的更新


421
00:13:43,916 --> 00:13:45,146
我们过去只支持


422
00:13:45,186 --> 00:13:46,716
单精度浮点权重


423
00:13:46,716 --> 00:13:47,026
类型


424
00:13:47,466 --> 00:13:49,076
现在为了帮你减少


425
00:13:49,076 --> 00:13:51,126
内存占用并


426
00:13:51,126 --> 00:13:51,966
提高网络


427
00:13:51,966 --> 00:13:52,326
性能


428
00:13:52,876 --> 00:13:54,546
我们还支持半精度


429
00:13:54,546 --> 00:13:56,466
浮点 8 位整数


430
00:13:56,806 --> 00:13:58,076
和二进制权重类型


431
00:13:59,496 --> 00:14:01,006
我们过去只支持标准


432
00:14:01,006 --> 00:14:02,676
卷积 现在


433
00:14:02,736 --> 00:14:03,926
我们也支持二进制和 
 
00:14:03,926 --> 00:14:04,646
XNOR 卷积


434
00:14:04,986 --> 00:14:06,096
扩张卷积


435
00:14:06,096 --> 00:14:08,406
子像素卷积和


436
00:14:08,406 --> 00:14:09,366
卷积转置


437
00:14:09,366 --> 00:14:09,996
操作


438
00:14:11,056 --> 00:14:12,156
其中许多是


439
00:14:12,156 --> 00:14:13,716
正交的 所以如果你愿意的话


440
00:14:14,006 --> 00:14:15,946
甚至可以进行 


441
00:14:15,946 --> 00:14:16,276
扩大子像素卷积


442
00:14:17,706 --> 00:14:18,486
让我们一个一个地


443
00:14:18,486 --> 00:14:19,046
看一下


444
00:14:20,806 --> 00:14:22,216
二进制和 XNOR 卷积


445
00:14:22,256 --> 00:14:24,276
与常规卷积执行


446
00:14:24,306 --> 00:14:26,336
相同的精确操作 但它们具有


447
00:14:26,336 --> 00:14:28,016
更好的性能 而且能够


448
00:14:28,476 --> 00:14:29,566
节省极大的空间


449
00:14:30,016 --> 00:14:31,726
所以在常规卷积中


450
00:14:31,726 --> 00:14:33,546
你可能有浮点输入


451
00:14:33,846 --> 00:14:35,166
和浮点权重


452
00:14:36,036 --> 00:14:37,446
而二进制卷积能够


453
00:14:37,516 --> 00:14:39,236
允许你


454
00:14:39,236 --> 00:14:41,266
使用二进制权重的全尺寸


455
00:14:41,266 --> 00:14:41,486
输入


456
00:14:42,416 --> 00:14:44,776
而对于 XNOR 卷积
 
00:14:44,776 --> 00:14:46,706
首先


457
00:14:47,226 --> 00:14:48,626
你的输入会被转换为


458
00:14:48,626 --> 00:14:50,826
二进制的 从而使输入


459
00:14:51,176 --> 00:14:52,396
和权重都是二进制的


460
00:14:53,476 --> 00:14:55,286
在常规卷积中
 
00:14:55,286 --> 00:14:57,066
输入必须与权重


461
00:14:57,106 --> 00:14:57,446
相乘


462
00:14:57,886 --> 00:14:59,876
而对于 XNOR 卷积


463
00:14:59,876 --> 00:15:01,806
分离变成了一个简单的 XNOR 


464
00:15:01,806 --> 00:15:02,336
操作


465
00:15:04,746 --> 00:15:06,066
现在我们来谈谈扩张


466
00:15:06,066 --> 00:15:06,656
卷积


467
00:15:07,626 --> 00:15:08,996
我们已经知道常规


468
00:15:08,996 --> 00:15:09,786
卷积如何工作


469
00:15:10,486 --> 00:15:12,396
你需要用过滤器对


470
00:15:12,396 --> 00:15:13,656
输入数据进行计算


471
00:15:13,656 --> 00:15:14,706
来得到单个输出值


472
00:15:17,526 --> 00:15:18,786
但如果你正在研究一种


473
00:15:18,786 --> 00:15:21,736
需要将更广泛的


474
00:15:21,736 --> 00:15:24,846
输入数据进行


475
00:15:25,216 --> 00:15:26,166
全局集成的算法
 
00:15:26,816 --> 00:15:28,466
那么你就不能用 3 乘 3 的内核


476
00:15:28,536 --> 00:15:30,496
而应该用一个 5 乘 5 的内核


477
00:15:31,736 --> 00:15:32,476
来进一步研究


478
00:15:33,026 --> 00:15:33,666
但是这样的话就要进行


479
00:15:33,666 --> 00:15:34,756
更加大量的计算


480
00:15:35,256 --> 00:15:37,266
另外一种方法是使用


481
00:15:37,266 --> 00:15:39,046
扩展卷积这样


482
00:15:39,046 --> 00:15:43,206
你就可以使用


483
00:15:43,206 --> 00:15:45,256
扩展因子在卷积


484
00:15:45,256 --> 00:15:46,836
内核里引入间隔


485
00:15:46,836 --> 00:15:48,836
从而可以


486
00:15:48,836 --> 00:15:50,576
只使用 3 乘 3 的内核


487
00:15:50,576 --> 00:15:52,676
就能够进行进一步的


488
00:15:52,676 --> 00:15:53,016
研究


489
00:15:54,996 --> 00:15:55,876
现在我们来谈谈


490
00:15:55,946 --> 00:15:57,266
亚光圈卷积和


491
00:15:57,266 --> 00:15:58,846
卷积转置原语
 
00:15:59,766 --> 00:16:01,266
常用于图像


492
00:16:01,266 --> 00:16:01,836
放大


493
00:16:03,066 --> 00:16:04,126
让我们想一下图象放大


494
00:16:04,176 --> 00:16:05,366
通常是如何进行的


495
00:16:05,456 --> 00:16:07,456
现在你有输入数据
 
00:16:07,516 --> 00:16:09,196
并想用因子 2 


496
00:16:09,196 --> 00:16:09,956
将其放大


497
00:16:12,336 --> 00:16:13,376
所以你将有一些


498
00:16:13,376 --> 00:16:14,566
缺失的像素需要计算


499
00:16:15,216 --> 00:16:16,536
并且通常扩大是


500
00:16:16,536 --> 00:16:18,156
用恒定过滤器进行的


501
00:16:18,156 --> 00:16:18,606
固定操作


502
00:16:18,766 --> 00:16:20,336
例如 盒式


503
00:16:20,336 --> 00:16:22,336
过滤器如何帮助你进行图像


504
00:16:22,386 --> 00:16:22,756
扩大


505
00:16:23,416 --> 00:16:25,146
盒式过滤器获取
 
00:16:25,316 --> 00:16:28,006
已知像素 并将


506
00:16:28,006 --> 00:16:29,326
已知的数据复制到缺失的


507
00:16:29,326 --> 00:16:30,786
位置从而获得


508
00:16:30,786 --> 00:16:31,216
扩大的结果


509
00:16:33,326 --> 00:16:35,196
对于子像素卷积
 
00:16:35,196 --> 00:16:36,646
你的过滤器不是常数


510
00:16:36,976 --> 00:16:38,226
过滤器会从数据中


511
00:16:38,226 --> 00:16:38,626
学习


512
00:16:38,766 --> 00:16:40,286
它们是经过训练的参数
 
00:16:40,716 --> 00:16:41,786
你可以从训练阶段


513
00:16:41,786 --> 00:16:42,906
获得这些参数 系统接受


514
00:16:42,986 --> 00:16:45,106
训练从而完成这个任务 


515
00:16:45,106 --> 00:16:45,946
完成图像扩大


516
00:16:47,086 --> 00:16:49,176
所以对于 2 倍放大有 4 个


517
00:16:49,236 --> 00:16:49,686
过滤器


518
00:16:49,806 --> 00:16:51,656
对于 4 倍放大有 16 个


519
00:16:51,656 --> 00:16:52,656
过滤器等等


520
00:16:53,566 --> 00:16:55,446
所以对于 2 倍放大


521
00:16:55,446 --> 00:16:57,456
我们需要用 4 个过滤器


522
00:16:57,456 --> 00:16:58,166
并把它应用在输入数据上


523
00:16:58,166 --> 00:17:00,216
然后对刚才的操作输出


524
00:17:00,216 --> 00:17:02,076
进行重新调整 从而获得


525
00:17:02,076 --> 00:17:03,476
最终的全分辨率


526
00:17:03,476 --> 00:17:03,856
图像


527
00:17:04,925 --> 00:17:06,445
现在让我们来谈谈


528
00:17:06,445 --> 00:17:08,076
如何使用卷积转置原语


529
00:17:08,156 --> 00:17:09,536
来放大图像


530
00:17:10,435 --> 00:17:12,026
我们有输入
 
00:17:12,026 --> 00:17:13,466
但还需要计算


531
00:17:13,465 --> 00:17:14,146
缺失的数据


532
00:17:14,945 --> 00:17:16,665
所以这个原语计算


533
00:17:17,156 --> 00:17:18,616
缺失数据的方法是
 
00:17:18,616 --> 00:17:19,586
它使用一种


534
00:17:19,586 --> 00:17:21,296
卷积传递给


535
00:17:21,296 --> 00:17:23,165
有间隙的中间结果
 
00:17:23,166 --> 00:17:24,596
然后计算每个输出像素


536
00:17:25,185 --> 00:17:27,316
这就是如何得到


537
00:17:27,356 --> 00:17:28,256
放大的结果


538
00:17:31,136 --> 00:17:32,216
现在我们将向你展示


539
00:17:32,216 --> 00:17:33,556
如何使用这些新的


540
00:17:33,556 --> 00:17:35,046
卷积原语在


541
00:17:35,046 --> 00:17:36,626
真实世界的网络中如何操作


542
00:17:37,096 --> 00:17:38,606
我们选用了这个着色


543
00:17:38,606 --> 00:17:41,486
网络 它可以输入黑白


544
00:17:41,486 --> 00:17:42,886
图像 然后输出


545
00:17:42,886 --> 00:17:44,356
彩色图像


546
00:17:44,356 --> 00:17:47,156
而这个特定的网络能够


547
00:17:47,236 --> 00:17:48,426
使用扩张卷积原语


548
00:17:48,426 --> 00:17:50,396
更快地整合更广泛


549
00:17:50,396 --> 00:17:52,296
全局环境


550
00:17:52,926 --> 00:17:54,756
并且它使用卷积


551
00:17:54,756 --> 00:17:56,726
转置原语来提高


552
00:17:56,726 --> 00:17:57,776e
网络的结果


553
00:18:00,166 --> 00:18:01,276
现在我们来看看这个


554
00:18:01,666 --> 00:18:03,966
着色网络怎样运行


555
00:18:10,226 --> 00:18:11,466
在这个演示中 我们


556
00:18:11,466 --> 00:18:12,886
收集了一些黑白


557
00:18:12,886 --> 00:18:14,046
图像 比如这个


558
00:18:14,046 --> 00:18:14,406
狮子


559
00:18:15,046 --> 00:18:16,416
一旦我点击这个


560
00:18:16,416 --> 00:18:17,796
图像 着色网络


561
00:18:17,796 --> 00:18:20,046
将在这个设备上


562
00:18:20,046 --> 00:18:21,126
运行 然后我们将看到一个


563
00:18:21,126 --> 00:18:21,946
彩色的图像


564
00:18:23,906 --> 00:18:25,456
让我们再试试另外一个例子
 
00:18:25,456 --> 00:18:27,046
这是一座美丽的雪山


565
00:18:27,046 --> 00:18:27,616
图像


566
00:18:28,836 --> 00:18:30,036
我们看到现在它是彩色的了


567
00:18:31,586 --> 00:18:33,756
还有这个美丽可爱的图像
 
00:18:33,756 --> 00:18:35,016
一位爸爸和女儿在弹


568
00:18:35,016 --> 00:18:35,366
吉他


569
00:18:35,366 --> 00:18:37,386
你可以看到现在图像


570
00:18:37,386 --> 00:18:38,026
是彩色的了


571
00:18:39,516 --> 00:18:40,896
还有这个图像我真的很喜欢


572
00:18:40,896 --> 00:18:42,306
一只棕熊在森林里


573
00:18:42,356 --> 00:18:42,696
散步


574
00:18:42,696 --> 00:18:43,756
所以我觉得这个网络


575
00:18:43,786 --> 00:18:45,146
效果非常不错


576
00:18:46,886 --> 00:18:48,726
好了 这就是现场


577
00:18:48,726 --> 00:18:48,916
演示
 
00:18:49,516 --> 00:18:54,686
[掌声]


578
00:18:55,186 --> 00:18:55,796
谢谢


579
00:18:57,766 --> 00:18:59,216
所以我们添加了所有这些新的


580
00:18:59,216 --> 00:19:01,456
卷积 CNN 原语 但


581
00:19:01,456 --> 00:19:02,056
这并不是全部


582
00:19:02,976 --> 00:19:04,666
我们还返回并改进了


583
00:19:04,666 --> 00:19:06,046
iOS 10 中可用的


584
00:19:06,206 --> 00:19:07,936
一些核心 CNN 内核


585
00:19:07,936 --> 00:19:09,646
的性能


586
00:19:10,406 --> 00:19:11,776
这个图像会显示


587
00:19:11,806 --> 00:19:13,846
Inception-v3 网络的


588
00:19:13,846 --> 00:19:15,386
性能 这是一种常用的


589
00:19:15,386 --> 00:19:16,936
图像识别


590
00:19:17,056 --> 00:19:17,546
网络


591
00:19:18,756 --> 00:19:20,396
它显示了这个网络


592
00:19:20,396 --> 00:19:22,196
在 iOS 11 中的性能


593
00:19:22,196 --> 00:19:23,786
正如你所看到的 我们


594
00:19:23,786 --> 00:19:25,866
在不同的 iOS 硬件上


595
00:19:25,866 --> 00:19:27,546
为你带来了至少 20％


596
00:19:27,756 --> 00:19:28,696
的性能提升


597
00:19:30,406 --> 00:19:33,786
现在我们来谈谈新的


598
00:19:33,786 --> 00:19:37,096
神经网络图像 API


599
00:19:37,716 --> 00:19:40,036
神经网络通常


600
00:19:40,036 --> 00:19:41,416
使用图像抽象化来


601
00:19:41,416 --> 00:19:42,476
描述 就像这个


602
00:19:42,476 --> 00:19:43,506
Inception-v3 网络的


603
00:19:43,506 --> 00:19:44,616
可视化一样


604
00:19:44,616 --> 00:19:46,696
我们现在可以使用


605
00:19:46,696 --> 00:19:48,706
新的图像 API 来做到


606
00:19:48,706 --> 00:19:48,966
这一点


607
00:19:50,446 --> 00:19:51,556
所以让我们将这些初始模块中的一个


608
00:19:51,556 --> 00:19:53,186
放大一下


609
00:19:54,676 --> 00:19:56,496
你有过滤节点可以


610
00:19:56,496 --> 00:19:58,176
描述对数据


611
00:19:58,176 --> 00:19:59,216
执行的操作


612
00:19:59,526 --> 00:20:01,146
比如卷积


613
00:20:01,146 --> 00:20:01,566
池化等


614
00:20:02,556 --> 00:20:04,316
同时你有图像节点


615
00:20:04,316 --> 00:20:05,736
可以描述数据如何在


616
00:20:05,786 --> 00:20:06,546
这些不同操作之间


617
00:20:06,546 --> 00:20:07,096
流动


618
00:20:07,826 --> 00:20:11,306
那么我们为什么要添加这个新的图像


619
00:20:11,306 --> 00:20:11,556
API 呢


620
00:20:11,926 --> 00:20:13,156
因为它很好使用


621
00:20:13,686 --> 00:20:14,656
你可以获得整个


622
00:20:14,656 --> 00:20:16,116
网络的紧凑


623
00:20:16,116 --> 00:20:18,326
表示 并将其保存到


624
00:20:18,326 --> 00:20:20,356
磁盘里 还可以将其还原


625
00:20:20,466 --> 00:20:21,546
它可以在平台间运行


626
00:20:23,166 --> 00:20:24,426
你只需要将图形


627
00:20:24,426 --> 00:20:26,366
进行一次初始化 然后就可以


628
00:20:26,366 --> 00:20:27,716
重新用在多个输入


629
00:20:27,716 --> 00:20:28,106
图像里了


630
00:20:29,516 --> 00:20:31,476
仅仅通过一次调用


631
00:20:31,476 --> 00:20:34,056
你就可以在 GPU 上对整个图形


632
00:20:34,056 --> 00:20:34,346
进行操作


633
00:20:36,276 --> 00:20:37,536
没有中间的图像


634
00:20:37,536 --> 00:20:39,196
需要管理 你只需要


635
00:20:39,196 --> 00:20:40,756
做好输入和


636
00:20:40,756 --> 00:20:41,036
输出


637
00:20:42,146 --> 00:20:45,016
在内部我们使用 Metal 堆


638
00:20:45,016 --> 00:20:46,796
来确保所有


639
00:20:46,796 --> 00:20:47,916
中间图像的


640
00:20:47,916 --> 00:20:49,506
内存占用


641
00:20:49,506 --> 00:20:50,126
尽可能小


642
00:20:50,606 --> 00:20:51,296
例如 对于


643
00:20:51,296 --> 00:20:53,376
Inception-v3 网络来说 


644
00:20:53,826 --> 00:20:56,856
这意味着能节省 5 倍的内存空间


645
00:20:56,856 --> 00:20:58,496
和 10 倍的检查器分配


646
00:20:58,556 --> 00:20:59,256
我觉得这是相当令人惊叹的


647
00:21:00,836 --> 00:21:02,926
正如我所说 图像为你


648
00:21:02,926 --> 00:21:03,956
做了所有的基础工作


649
00:21:04,316 --> 00:21:05,646
它会创建


650
00:21:05,846 --> 00:21:06,846
中间图像


651
00:21:06,996 --> 00:21:08,706
并管理图像的大小


652
00:21:09,296 --> 00:21:11,086
它甚至会管理


653
00:21:11,086 --> 00:21:11,366
输出的大小


654
00:21:11,786 --> 00:21:12,766
它负责处理


655
00:21:12,766 --> 00:21:13,406
填充策略


656
00:21:13,796 --> 00:21:15,016
它也会进行审查


657
00:21:15,426 --> 00:21:17,516
简而言之 它能让你


658
00:21:17,566 --> 00:21:19,406
少写很多代码


659
00:21:19,486 --> 00:21:20,746
也就能避免产生很多


660
00:21:20,746 --> 00:21:20,956
错误


661
00:21:21,956 --> 00:21:24,066
当我说较少的代码时 


662
00:21:24,596 --> 00:21:25,376
我是说少了非常多的代码


663
00:21:26,206 --> 00:21:27,906
所以去年我们发布了


664
00:21:27,996 --> 00:21:30,726
使用 Inception-v3 网络


665
00:21:30,726 --> 00:21:32,036
进行图像识别的 Metal 


666
00:21:32,036 --> 00:21:33,286
识别样本


667
00:21:34,326 --> 00:21:36,026
我们把这个样本


668
00:21:36,026 --> 00:21:37,576
转换了一下 从而能够使用


669
00:21:37,806 --> 00:21:40,036
新的图像 API 然后发现我们


670
00:21:40,036 --> 00:21:41,956
可以少编写四倍的代码


671
00:21:42,356 --> 00:21:43,956
少写的代码行数与为了


672
00:21:43,956 --> 00:21:45,846
执行相同的网络


673
00:21:46,226 --> 00:21:47,916
需要在开源传感器


674
00:21:47,916 --> 00:21:48,886
流程框架中编写的


675
00:21:48,886 --> 00:21:50,436
Python 代码行数


676
00:21:50,436 --> 00:21:50,846
一样多


677
00:21:51,476 --> 00:21:52,956
我们只是想提一下 


678
00:21:52,956 --> 00:21:54,046
我们将发布这个升级的


679
00:21:54,086 --> 00:21:57,196
示例代码 升级的示例作为


680
00:21:57,196 --> 00:21:58,346
示例代码


681
00:21:59,026 --> 00:22:01,796
拥有关于你的整个网络的


682
00:22:01,796 --> 00:22:03,276
所有信息 使我们能够


683
00:22:03,276 --> 00:22:06,116
在不同的视图中


684
00:22:06,116 --> 00:22:07,956
提供最佳


685
00:22:08,106 --> 00:22:08,866
性能


686
00:22:09,336 --> 00:22:10,946
让你可以轻松地在


687
00:22:10,946 --> 00:22:12,766
CPU 和 GPU 之间进行


688
00:22:12,766 --> 00:22:13,206
并行处理


689
00:22:13,976 --> 00:22:15,876
当图像正在执行  


690
00:22:16,326 --> 00:22:18,076
当 GPU 执行一个


691
00:22:18,076 --> 00:22:19,986
输入图像的图形时


692
00:22:19,986 --> 00:22:21,686
CPU 已经准备好执行


693
00:22:21,686 --> 00:22:22,776
不同的输入


694
00:22:22,776 --> 00:22:23,716
图像图形了


695
00:22:25,176 --> 00:22:26,606
我们还可以将图形节点


696
00:22:26,676 --> 00:22:28,446
融合在一起 比如卷积和


697
00:22:28,856 --> 00:22:29,966
神经元节点


698
00:22:31,856 --> 00:22:33,746
我们可以同时操作


699
00:22:33,746 --> 00:22:34,386
这些图形节点


700
00:22:34,386 --> 00:22:36,256
所以如果我们再看一下


701
00:22:36,256 --> 00:22:38,056
这个初始模块的话 


702
00:22:38,056 --> 00:22:39,886
你就可以看到很多行


703
00:22:39,886 --> 00:22:41,386
节点可以


704
00:22:41,456 --> 00:22:43,036
完全彼此独立的


705
00:22:43,036 --> 00:22:43,236
操作


706
00:22:44,176 --> 00:22:45,486
当然 这些独立执行的


707
00:22:45,486 --> 00:22:47,326
输出需要通过


708
00:22:47,926 --> 00:22:49,216
相关节点进行


709
00:22:49,216 --> 00:22:50,216
连接


710
00:22:51,206 --> 00:22:52,656
而且这个图像也足够智能


711
00:22:52,656 --> 00:22:54,276
可以将这些进行优化处理


712
00:22:54,886 --> 00:22:57,706
现在我们来看看如何使用


713
00:22:57,706 --> 00:22:59,586
新的图形 API


714
00:23:00,296 --> 00:23:02,176
所以这是使用


715
00:23:02,176 --> 00:23:04,126
图形 API 创建


716
00:23:04,126 --> 00:23:04,646
卷积节点的代码


717
00:23:05,826 --> 00:23:07,256
它需要一个图像作为源 


718
00:23:08,226 --> 00:23:09,486
而且它也有权重


719
00:23:09,486 --> 00:23:10,926
所以让我们谈一下


720
00:23:10,926 --> 00:23:11,176
权重


721
00:23:13,056 --> 00:23:14,256
神经网络规模


722
00:23:14,256 --> 00:23:15,396
变得越来越大


723
00:23:16,136 --> 00:23:17,736
如果你的网络中有


724
00:23:17,736 --> 00:23:19,346
很多卷积节点 


725
00:23:19,346 --> 00:23:21,436
那就意味着


726
00:23:21,496 --> 00:23:22,466
你的整个网络的


727
00:23:22,466 --> 00:23:23,616
总体权重可能


728
00:23:23,616 --> 00:23:24,246
相当大


729
00:23:25,216 --> 00:23:27,016
为了解决这个问题


730
00:23:27,016 --> 00:23:30,126
我们添加了一个


731
00:23:30,186 --> 00:23:31,296
可以执行的卷积数据源协议


732
00:23:31,656 --> 00:23:33,186
它能够及时


733
00:23:33,606 --> 00:23:35,036
加载和清除


734
00:23:35,076 --> 00:23:35,276
权重数据


735
00:23:36,296 --> 00:23:40,046
所以我们的想法是


736
00:23:40,046 --> 00:23:41,546
你的整个网络的


737
00:23:41,546 --> 00:23:43,196
权重就不用同时


738
00:23:43,196 --> 00:23:44,086
全部加载到内存中


739
00:23:44,626 --> 00:23:45,956
它们也不必


740
00:23:45,956 --> 00:23:46,886
提前加载


741
00:23:48,396 --> 00:23:49,656
为了帮助将内存空间


742
00:23:49,656 --> 00:23:51,556
占用降到最小 当我们初始化


743
00:23:51,556 --> 00:23:53,136
图形并处理


744
00:23:53,136 --> 00:23:54,516
一个特定的卷积层时


745
00:23:55,096 --> 00:23:56,126
我们将为这个卷积层


746
00:23:56,126 --> 00:23:57,726
加载权重 然后


747
00:23:57,856 --> 00:23:59,486
将它们清除之后


748
00:23:59,486 --> 00:24:00,726
再进入下一个卷积层


749
00:24:02,226 --> 00:24:03,586
你要做的就是使用


750
00:24:03,586 --> 00:24:05,146
这个初始化方法


751
00:24:05,146 --> 00:24:06,916
它知道数据的


752
00:24:06,916 --> 00:24:08,376
位置 但实际上并不会


753
00:24:08,376 --> 00:24:09,086
加载数据


754
00:24:10,096 --> 00:24:11,256
然后当图像调用


755
00:24:11,256 --> 00:24:13,266
加载功能的时候 


756
00:24:13,266 --> 00:24:14,846
会提醒你需要


757
00:24:14,846 --> 00:24:15,236
加载权重


758
00:24:15,366 --> 00:24:16,546
然后当图像调用


759
00:24:16,546 --> 00:24:18,166
清除函数功能时


760
00:24:18,166 --> 00:24:19,316
你可以释放权重


761
00:24:21,586 --> 00:24:22,526
现在我们来构建一个图像


762
00:24:23,446 --> 00:24:24,926
这里我们正在使用


763
00:24:24,926 --> 00:24:26,116
这个 makeGraph 函数


764
00:24:26,596 --> 00:24:28,366
而在左边 你可以看到


765
00:24:28,366 --> 00:24:29,636
构建网络所需的


766
00:24:29,636 --> 00:24:30,826
所有节点


767
00:24:31,256 --> 00:24:32,926
然后我们创建节点


768
00:24:33,226 --> 00:24:34,446
创建卷积


769
00:24:34,446 --> 00:24:34,836
节点


770
00:24:35,016 --> 00:24:35,616
池化节点


771
00:24:35,616 --> 00:24:37,456
和剩下的节点


772
00:24:37,756 --> 00:24:38,606
现在节点有了


773
00:24:38,606 --> 00:24:40,226
那我们如何将节点


774
00:24:40,226 --> 00:24:40,446
连接成图像呢


775
00:24:41,646 --> 00:24:43,186
我们只需把一个节点的


776
00:24:43,186 --> 00:24:44,986
结果图像作为


777
00:24:45,066 --> 00:24:46,516
源图像传递给下一个节点 


778
00:24:46,516 --> 00:24:48,106
就形成了图像


779
00:24:49,736 --> 00:24:51,236
现在让我们在 GPU 上运行这个图表


780
00:24:51,906 --> 00:24:54,066
首先像往常一样进行 Metal 


781
00:24:54,066 --> 00:24:54,456
设置


782
00:24:54,886 --> 00:24:56,016
我们初始化这个图像


783
00:24:56,676 --> 00:24:58,166
要管理好输入数据


784
00:24:58,866 --> 00:25:01,066
然后将图像编码到


785
00:25:01,066 --> 00:25:01,506
GPU 上


786
00:25:02,276 --> 00:25:04,026
输出图像中的数据


787
00:25:04,556 --> 00:25:06,546
将会在命令缓冲区


788
00:25:06,546 --> 00:25:08,466
完成时 将数据填充到


789
00:25:08,466 --> 00:25:09,576
输出图像中


790
00:25:10,086 --> 00:25:11,526
然后我们可以选择


791
00:25:11,526 --> 00:25:12,996
等待 GPU 完成


792
00:25:13,406 --> 00:25:14,686
但我们并不推荐


793
00:25:14,686 --> 00:25:14,956
这样做


794
00:25:15,886 --> 00:25:17,506
因为如果这样做的话 


795
00:25:17,506 --> 00:25:19,246
CPU 就会等 GPU 完成之后 


796
00:25:19,836 --> 00:25:21,486
才能开始对下一轮


797
00:25:21,486 --> 00:25:22,846
图像进行编码


798
00:25:23,486 --> 00:25:25,256
而这样会将气泡引入你的


799
00:25:25,256 --> 00:25:26,266
传输途径 并对


800
00:25:26,526 --> 00:25:28,036
性能产生不利影响


801
00:25:29,816 --> 00:25:30,686
所以我们推荐


802
00:25:30,686 --> 00:25:32,606
使用新的


803
00:25:32,606 --> 00:25:34,596
异步执行的 API


804
00:25:35,426 --> 00:25:37,896
使用这个 API 能让你的 Metal 


805
00:25:37,966 --> 00:25:39,436
设置甚至变得更小


806
00:25:39,626 --> 00:25:41,076
这样你只需要准备好


807
00:25:41,076 --> 00:25:41,736
Metal 设备


808
00:25:42,136 --> 00:25:43,096
然后需要


809
00:25:43,096 --> 00:25:44,016
初始化图像


810
00:25:44,056 --> 00:25:46,426
准备好输入数据 然后


811
00:25:46,426 --> 00:25:47,856
执行异步调用


812
00:25:49,586 --> 00:25:52,376
它会立即返回 


813
00:25:52,376 --> 00:25:54,216
然后当这个代码


814
00:25:55,196 --> 00:25:56,236
闭包执行时 输出图像


815
00:25:56,236 --> 00:25:57,086
就已经准备好了


816
00:25:57,796 --> 00:25:59,056
但在此期间 你不需要


817
00:25:59,056 --> 00:26:00,136
等待 GPU 完成


818
00:26:00,306 --> 00:26:02,056
就可以继续进行


819
00:26:02,056 --> 00:26:03,676
编码和新的 GPU 任务。


820
00:26:04,396 --> 00:26:07,236
这样 CPU 和 GPU 就


821
00:26:07,236 --> 00:26:08,846
可以同时工作


822
00:26:09,406 --> 00:26:10,316
并且你的传输途经中


823
00:26:10,316 --> 00:26:12,756
没有气泡 两者都


824
00:26:12,756 --> 00:26:14,376
被充分地利用了起来


825
00:26:16,756 --> 00:26:18,996
好了 现在我来做一次


826
00:26:18,996 --> 00:26:21,106
现场演示 演示


827
00:26:21,146 --> 00:26:22,846
同步和异步 API 


828
00:26:22,966 --> 00:26:24,526
之间的


829
00:26:24,526 --> 00:26:24,786
性能差异


830
00:26:24,786 --> 00:26:27,576
这个演示将使用


831
00:26:27,576 --> 00:26:29,576
Inception-v3 网络


832
00:26:29,576 --> 00:26:30,116
进行图像识别


833
00:26:30,516 --> 00:26:30,806
好的


834
00:26:31,136 --> 00:26:32,726
我将从同步


835
00:26:32,726 --> 00:26:34,416
API 开始 在这里我们正在


836
00:26:34,416 --> 00:26:35,706
检测一个水瓶


837
00:26:35,706 --> 00:26:38,276
平均每个


838
00:26:38,276 --> 00:26:41,756
图像大约有 50 


839
00:26:41,756 --> 00:26:42,596
毫秒


840
00:26:42,826 --> 00:26:44,066
现在我将切换到


841
00:26:44,066 --> 00:26:44,956
异步 API


842
00:26:44,956 --> 00:26:47,586
现在平均每个图像的


843
00:26:47,586 --> 00:26:49,546
时间约为 36 


844
00:26:49,546 --> 00:26:49,936
毫秒


845
00:26:49,936 --> 00:26:51,656
所以性能


846
00:26:51,686 --> 00:26:52,666
有了很大提升


847
00:26:54,776 --> 00:26:55,066
好的


848
00:26:55,196 --> 00:26:56,436
这就是现场演示


849
00:26:58,516 --> 00:27:04,016
[掌声]


850
00:27:04,516 --> 00:27:04,876
谢谢你们


851
00:27:06,566 --> 00:27:07,656
好的 既然我们已经谈过了


852
00:27:07,656 --> 00:27:08,626
新的神经网络图像


853
00:27:08,626 --> 00:27:10,926
API 并且向你展示了


854
00:27:10,956 --> 00:27:12,716
它使用起来多么简单


855
00:27:12,716 --> 00:27:14,016
性能多么强大 


856
00:27:14,016 --> 00:27:16,086
现在让我们来换个话题 


857
00:27:16,086 --> 00:27:17,166
谈谈循环神经


858
00:27:17,166 --> 00:27:17,566
网络


859
00:27:19,416 --> 00:27:20,386
什么是循环神经


860
00:27:20,386 --> 00:27:20,786
网络呢


861
00:27:23,406 --> 00:27:25,456
CNN 的一个缺点是


862
00:27:25,456 --> 00:27:27,276
无法记住过去


863
00:27:27,306 --> 00:27:28,326
发生的


864
00:27:28,326 --> 00:27:28,466
事情


865
00:27:29,456 --> 00:27:31,226
它们可以将一个图像


866
00:27:31,896 --> 00:27:33,926
作为输入 并生成单个输出


867
00:27:34,446 --> 00:27:36,316
例如图像中所描绘


868
00:27:36,356 --> 00:27:37,396
内容的一组


869
00:27:37,396 --> 00:27:37,836
可能性


870
00:27:39,056 --> 00:27:41,016
但 RNN 是有


871
00:27:41,016 --> 00:27:41,446
记忆的


872
00:27:42,346 --> 00:27:43,466
而且它们擅长按顺序


873
00:27:43,546 --> 00:27:44,066
进行操作


874
00:27:44,536 --> 00:27:48,256
所以它们可以通过一个输入


875
00:27:48,256 --> 00:27:49,576
比如图像中所


876
00:27:49,636 --> 00:27:51,016
描绘内容的一组


877
00:27:51,616 --> 00:27:52,966
可能性 然后产生一个


878
00:27:53,036 --> 00:27:53,366
输出序列


879
00:27:53,366 --> 00:27:56,196
一组有逻辑顺序的单词


880
00:27:56,196 --> 00:27:57,586
成为这个图像的标题


881
00:27:59,416 --> 00:28:01,716
它们还可以通过一个


882
00:28:01,806 --> 00:28:03,506
序列输入 比如英语句子 


883
00:28:03,506 --> 00:28:06,626
产生多个序列


884
00:28:06,626 --> 00:28:08,506
输出 比如同一个句子翻译成


885
00:28:08,666 --> 00:28:09,946
不同的语言 


886
00:28:09,946 --> 00:28:12,376
比如俄语


887
00:28:12,466 --> 00:28:13,056
或芬兰语


888
00:28:13,366 --> 00:28:16,356
而且我们还支持许多


889
00:28:16,356 --> 00:28:17,756
不同的 RNN 变体


890
00:28:18,586 --> 00:28:20,146
单门限 RNN 


891
00:28:20,146 --> 00:28:22,156
长短期记忆 RNN 或者说 LSTM 


892
00:28:22,596 --> 00:28:24,586
以及 LSTM 的多种变体


893
00:28:24,866 --> 00:28:26,336
GRU 和 MGU


894
00:28:27,766 --> 00:28:29,336
那么让我们来谈谈最简单的


895
00:28:29,366 --> 00:28:31,326
RNN 类型 单门限


896
00:28:31,326 --> 00:28:31,526
RNN


897
00:28:33,666 --> 00:28:34,966
单门限 RNN 具有


898
00:28:34,966 --> 00:28:37,006
循环单元 这使得


899
00:28:37,066 --> 00:28:38,676
RNN 之前的输出


900
00:28:38,996 --> 00:28:40,346
能够影响同一个


901
00:28:40,406 --> 00:28:41,846
RNN 的后续


902
00:28:41,846 --> 00:28:42,406
迭代输出


903
00:28:43,606 --> 00:28:45,496
但是单门限 RNN 的功能


904
00:28:45,546 --> 00:28:47,466
还不够强大 不能将


905
00:28:47,466 --> 00:28:48,746
重要信息对多次


906
00:28:48,746 --> 00:28:49,286
迭代输出构成影响


907
00:28:50,136 --> 00:28:51,676
因为单门限 RNN 的


908
00:28:51,786 --> 00:28:53,976
当前输出也是


909
00:28:53,976 --> 00:28:54,996
它的当前状态


910
00:28:54,996 --> 00:28:55,976
没有别的东西


911
00:28:57,146 --> 00:28:59,426
解决这个问题的方法是


912
00:28:59,476 --> 00:29:01,596
长短期记忆 RNN 或简称 LSTM


913
00:29:02,376 --> 00:29:03,906
它由单门限 RNN 构成 


914
00:29:03,906 --> 00:29:06,246
并具有内部存储


915
00:29:06,246 --> 00:29:06,506
单元


916
00:29:07,436 --> 00:29:08,856
一个特定的


917
00:29:08,956 --> 00:29:10,596
门限组合可以控制


918
00:29:10,596 --> 00:29:13,106
信息在 LSTM 内如何流动


919
00:29:13,436 --> 00:29:15,016
并有选择的让信息


920
00:29:15,136 --> 00:29:16,266
存入存储单元


921
00:29:16,846 --> 00:29:19,656
让我们更详细地


922
00:29:19,656 --> 00:29:21,316
看一下 LSTM 的


923
00:29:21,316 --> 00:29:21,776
架构


924
00:29:22,206 --> 00:29:25,246
正如我所说 LSTM 中


925
00:29:25,356 --> 00:29:27,846
最重要的实体是存储


926
00:29:27,886 --> 00:29:30,406
单元 它在 LSTM 的每个循环期内


927
00:29:30,476 --> 00:29:31,536
都会进行更新


928
00:29:31,536 --> 00:29:33,426
所以你可以想到 


929
00:29:33,846 --> 00:29:35,246
LSTM 的每一次迭代


930
00:29:35,306 --> 00:29:37,456
都是这种新旧


931
00:29:37,456 --> 00:29:38,016
内存之间的转换


932
00:29:38,676 --> 00:29:40,786
现在让我们谈谈


933
00:29:40,816 --> 00:29:41,036
门限


934
00:29:41,566 --> 00:29:43,376
首先是遗忘门限 


935
00:29:44,216 --> 00:29:45,876
它决定旧的内存中


936
00:29:45,876 --> 00:29:47,206
哪些能够保留


937
00:29:47,206 --> 00:29:47,566
哪些不能保留


938
00:29:48,966 --> 00:29:50,456
然后是输入和


939
00:29:50,456 --> 00:29:51,836
单元门限


940
00:29:51,836 --> 00:29:53,996
它们的相互组合决定了


941
00:29:54,066 --> 00:29:55,786
当前输入的什么信息


942
00:29:55,786 --> 00:29:56,936
将影响新的内存


943
00:29:56,936 --> 00:29:59,136
然后这三个门限


944
00:29:59,136 --> 00:30:00,866
组合在一起来


945
00:30:01,226 --> 00:30:04,596
更新存储单元


946
00:30:05,696 --> 00:30:07,576
最后是输出门限


947
00:30:07,626 --> 00:30:09,656
它决定了


948
00:30:09,656 --> 00:30:11,976
以前的输入


949
00:30:12,476 --> 00:30:14,076
输出 当前的


950
00:30:14,076 --> 00:30:16,126
输入和新的内存中


951
00:30:16,126 --> 00:30:17,936
哪些信息将会影响 LSTM 的输出


952
00:30:19,196 --> 00:30:20,626
所以现在你知道 LSTM 


953
00:30:20,626 --> 00:30:22,206
是由什么组成的了 让我们来看看


954
00:30:22,206 --> 00:30:24,006
你如何使用我们的框架


955
00:30:24,006 --> 00:30:24,576
来创建一个 LSTM


956
00:30:25,616 --> 00:30:27,536
首先创建一个 LSTM 的


957
00:30:27,756 --> 00:30:28,576
描述符


958
00:30:29,146 --> 00:30:31,306
然后你需要将门限


959
00:30:31,526 --> 00:30:31,876
初始化


960
00:30:32,436 --> 00:30:33,676
那么门限由什么控制呢 


961
00:30:33,676 --> 00:30:35,146
什么能够控制门限


962
00:30:35,306 --> 00:30:36,156
控制门限


963
00:30:36,156 --> 00:30:37,756
如何操作的是经过


964
00:30:37,756 --> 00:30:38,386
训练的参数


965
00:30:39,146 --> 00:30:40,156
这些参数来自


966
00:30:40,156 --> 00:30:41,726
为使系统执行一项特定任务


967
00:30:41,726 --> 00:30:43,526
而对其进行训练的步骤


968
00:30:45,566 --> 00:30:47,496
而且你可以看到 


969
00:30:47,496 --> 00:30:48,586
这里有很多门限


970
00:30:48,646 --> 00:30:49,856
供你进行初始化


971
00:30:49,856 --> 00:30:52,356
但为了简要说明


972
00:30:52,356 --> 00:30:52,726
我们只展示两个初始化


973
00:30:53,206 --> 00:30:54,336
正如你所看到的 我们也


974
00:30:54,336 --> 00:30:56,046
在使用一个数据源供应程序 


975
00:30:56,046 --> 00:30:57,446
和之前给你看过的一样


976
00:30:57,556 --> 00:30:58,606
它用来初始化权重


977
00:30:59,656 --> 00:31:01,536
下一步是创建


978
00:31:01,536 --> 00:31:03,606
我们的 LSTM 层 现在我们


979
00:31:03,606 --> 00:31:04,876
把它放在 GPU 上运行


980
00:31:06,586 --> 00:31:08,646
我们需要创建数组 


981
00:31:08,646 --> 00:31:10,976
保存 LSTM 


982
00:31:10,976 --> 00:31:13,236
执行序列的


983
00:31:13,236 --> 00:31:14,266
输入和输出


984
00:31:14,886 --> 00:31:16,076
然后将序列编码到


985
00:31:16,076 --> 00:31:16,716
GPU 上


986
00:31:17,416 --> 00:31:19,446
在这里 我们向你展示


987
00:31:19,666 --> 00:31:21,546
一种基于矩阵的 RNN 但我们


988
00:31:21,546 --> 00:31:22,646
想提一下 我们


989
00:31:22,686 --> 00:31:25,726
也支持通过卷积在


990
00:31:25,726 --> 00:31:27,636
MPS 图像上操作的 RNN


991
00:31:30,176 --> 00:31:31,216
现在我们来看一个


992
00:31:31,216 --> 00:31:32,016
实际的例子


993
00:31:32,596 --> 00:31:34,366
我们将使用图片字幕


994
00:31:34,366 --> 00:31:35,706
作为使用 LSTM 的例子


995
00:31:36,726 --> 00:31:38,566
你应该记得 我跟你讲过 


996
00:31:38,896 --> 00:31:40,646
深度学习算法


997
00:31:40,646 --> 00:31:42,076
有两个阶段


998
00:31:42,346 --> 00:31:43,316
训练阶段和


999
00:31:43,316 --> 00:31:44,026
推理阶段


1000
00:31:44,816 --> 00:31:46,816
所以要想训练一个系统


1001
00:31:46,816 --> 00:31:49,196
为图像添加说明文字


1002
00:31:49,196 --> 00:31:51,056
你需要给它输入大量的带有


1003
00:31:51,056 --> 00:31:52,356
人为添加说明文字的图像


1004
00:31:53,836 --> 00:31:56,606
那么这个系统有什么呢


1005
00:31:56,656 --> 00:31:57,686
它是由什么构成的


1006
00:31:58,536 --> 00:32:02,016
这个系统有一个 CNN 和一个


1007
00:32:02,016 --> 00:32:03,906
RNN 一起工作来生成


1008
00:32:03,906 --> 00:32:04,346
说明文字


1009
00:32:04,746 --> 00:32:07,316
CNN 用于确定


1010
00:32:07,316 --> 00:32:09,316
图像中描述的内容


1011
00:32:09,316 --> 00:32:10,886
然后经 RNN 生成


1012
00:32:10,956 --> 00:32:11,806
实际的说明文字


1013
00:32:13,256 --> 00:32:15,076
而该过程的输出


1014
00:32:15,156 --> 00:32:17,006
是经过训练的参数


1015
00:32:17,006 --> 00:32:19,036
它们是下一步也就是


1016
00:32:20,186 --> 00:32:20,886
推理阶段需要的


1017
00:32:21,676 --> 00:32:25,606
因此 在推理阶段


1018
00:32:25,656 --> 00:32:27,766
经过训练的参数控制


1019
00:32:27,766 --> 00:32:29,826
CNN 层


1020
00:32:29,826 --> 00:32:31,866
和 RNN 


1021
00:32:31,866 --> 00:32:32,146.
门限的运行


1022
00:32:33,206 --> 00:32:37,276
然后每个图像


1023
00:32:37,336 --> 00:32:39,166
都由 CNN 和 RNN 进行处理


1024
00:32:39,446 --> 00:32:41,326
从而生成说明文字


1025
00:32:42,216 --> 00:32:43,246
我们已经知道有一个很好的


1026
00:32:43,246 --> 00:32:44,636
网络可以确定


1027
00:32:44,706 --> 00:32:45,816
图像中描绘的内容


1028
00:32:46,086 --> 00:32:47,506
就是 Inception-v3 网络


1029
00:32:47,876 --> 00:32:48,626
所以我们将使用它


1030
00:32:49,186 --> 00:32:50,456
而且我们刚刚谈到了 LSTM


1031
00:32:50,456 --> 00:32:52,236
所以让我们用它来生成


1032
00:32:52,446 --> 00:32:53,036
说明文字


1033
00:32:53,996 --> 00:32:56,456
说明文字生成阶段


1034
00:32:57,266 --> 00:32:58,176
说明文字生成过程


1035
00:32:58,176 --> 00:32:59,726
也分为两个阶段


1036
00:33:00,006 --> 00:33:02,206
首先我们有 LSTM 


1037
00:33:02,486 --> 00:33:03,646
初始化阶段


1038
00:33:04,846 --> 00:33:06,126
然后我们运行 Inception-v3 


1039
00:33:06,126 --> 00:33:08,616
网络 实际上我们运行了所有的


1040
00:33:08,616 --> 00:33:10,496
层 除了最后一个


1041
00:33:10,496 --> 00:33:11,986
SoftMax 层


1042
00:33:12,236 --> 00:33:13,386
而输出是一个


1043
00:33:13,386 --> 00:33:15,016
特征向量 它含有


1044
00:33:15,016 --> 00:33:16,196
关于图像描绘


1045
00:33:16,196 --> 00:33:17,226
内容的信息


1046
00:33:17,906 --> 00:33:19,016
然后我们将该


1047
00:33:19,016 --> 00:33:20,566
特征向量转换为


1048
00:33:20,566 --> 00:33:23,246
LSTM 所需的


1049
00:33:23,246 --> 00:33:24,286
紧凑表示


1050
00:33:24,286 --> 00:33:26,596
然后通过 LSTM 运行


1051
00:33:26,946 --> 00:33:27,746
将其初始化


1052
00:33:28,736 --> 00:33:30,466
然后一旦我们有了


1053
00:33:30,466 --> 00:33:32,436
初始化的 LSTM 那就


1054
00:33:32,436 --> 00:33:33,586
准备好可以进入下一个阶段了


1055
00:33:34,606 --> 00:33:36,066
即实际说明文字


1056
00:33:36,066 --> 00:33:36,376
生成阶段


1057
00:33:38,116 --> 00:33:39,676
我们通过向 LSTM 传递


1058
00:33:39,676 --> 00:33:41,366
一个特殊的句子开始令牌 ID 


1059
00:33:41,436 --> 00:33:44,026
来启动这个过程


1060
00:33:44,236 --> 00:33:45,046
并且该操作的输出


1061
00:33:45,046 --> 00:33:46,756
是一个单词序列


1062
00:33:46,756 --> 00:33:50,006
你知道的 就是


1063
00:33:50,006 --> 00:33:51,276
和图像中所描绘的


1064
00:33:51,276 --> 00:33:52,666
内容相关的单词


1065
00:33:53,526 --> 00:33:55,806
然后我们将这些单词传递给


1066
00:33:55,806 --> 00:33:57,226
一个 SoftMax 层 该层可以计算


1067
00:33:57,226 --> 00:33:58,796
这些单词的概率


1068
00:33:59,326 --> 00:34:01,176
我们选择三个概率最高的


1069
00:34:01,326 --> 00:34:03,276
这三个概率最高的单词也是


1070
00:34:03,276 --> 00:34:05,816
我们对于特定图像的


1071
00:34:05,816 --> 00:34:07,546
说明文字中的单字部分


1072
00:34:08,126 --> 00:34:09,726
所以我们将这些单词拿出来


1073
00:34:09,806 --> 00:34:11,856
并传递给下一个状态的


1074
00:34:11,946 --> 00:34:15,045
LSTM 它的功能是


1075
00:34:15,096 --> 00:34:16,886
为图像算出三组


1076
00:34:16,916 --> 00:34:19,216
最好的双字组合


1077
00:34:19,216 --> 00:34:19,386
说明文字


1078
00:34:19,466 --> 00:34:21,416
我们执行 N 次迭代 


1079
00:34:21,886 --> 00:34:23,076
直到达到停止的


1080
00:34:23,076 --> 00:34:25,596
条件 也就是当


1081
00:34:25,626 --> 00:34:27,116
达到我们想要的说明文字


1082
00:34:27,116 --> 00:34:28,966
字数上限的时候 


1083
00:34:28,966 --> 00:34:30,856
或者当


1084
00:34:30,856 --> 00:34:32,136
新生成的说明文字


1085
00:34:32,136 --> 00:34:33,906
概率下降到 0 的时候


1086
00:34:34,985 --> 00:34:35,996
我知道这仍然


1087
00:34:35,996 --> 00:34:36,505
很抽象


1088
00:34:36,846 --> 00:34:39,005
所以让我们来看看


1089
00:34:39,386 --> 00:34:42,266
LSTM 的输出 也就是


1090
00:34:42,326 --> 00:34:44,556
LSTM 为了一个特定图像


1091
00:34:44,556 --> 00:34:45,545
进行多次迭代之后的实际输出


1092
00:34:46,216 --> 00:34:49,786
在这个图像中 你看到


1093
00:34:49,786 --> 00:34:51,636
有冲浪者驾驭在一个波浪上


1094
00:34:51,636 --> 00:34:53,146
我们想计算出匹配这张图像的


1095
00:34:53,146 --> 00:34:54,666
三句最好的说明文字


1096
00:34:55,696 --> 00:34:57,286
在 LSTM 的第一次迭代中


1097
00:34:57,366 --> 00:34:59,936
生成了三个最好的


1098
00:34:59,936 --> 00:35:00,306
单词


1099
00:35:02,336 --> 00:35:04,446
所以 这是匹配


1100
00:35:04,446 --> 00:35:05,686
这张图像的最好的


1101
00:35:05,686 --> 00:35:05,996
文字说明


1102
00:35:06,506 --> 00:35:07,596
“man”“a”和“the”


1103
00:35:08,316 --> 00:35:10,596
“a”一词的概率


1104
00:35:10,596 --> 00:35:11,186
最高


1105
00:35:11,936 --> 00:35:13,546
然后我们把这三个字


1106
00:35:13,546 --> 00:35:15,196
传递给下一个


1107
00:35:15,196 --> 00:35:16,436
LSTM 的迭代


1108
00:35:17,166 --> 00:35:19,356
在这个迭代中 


1109
00:35:19,356 --> 00:35:21,416
对于这三个起始单词中的


1110
00:35:22,436 --> 00:35:24,416
每一个 LSTM 都生成了三个新词 


1111
00:35:24,416 --> 00:35:26,026
它们有和这些


1112
00:35:26,026 --> 00:35:28,496
起始单词组合的


1113
00:35:28,496 --> 00:35:29,606
最高概率


1114
00:35:30,666 --> 00:35:31,966
对吧 所以我们有三个


1115
00:35:31,966 --> 00:35:33,556
新词可以和“man”组合


1116
00:35:33,946 --> 00:35:35,256
三个新词和“a”


1117
00:35:35,256 --> 00:35:37,766
组合 还有三个新词


1118
00:35:37,826 --> 00:35:38,976
和“the”组合


1119
00:35:40,686 --> 00:35:42,296
现在你可以看到 


1120
00:35:42,296 --> 00:35:44,486
每一个双字组合说明


1121
00:35:44,486 --> 00:35:45,486
也都有概率


1122
00:35:46,026 --> 00:35:47,866
而且由于“a” 


1123
00:35:47,936 --> 00:35:49,286
在第一次迭代中具有


1124
00:35:49,286 --> 00:35:53,366
如此高的概率 所以


1125
00:35:53,366 --> 00:35:54,646
在第二次迭代中


1126
00:35:54,646 --> 00:35:56,426
以“a”开头的双字组合


1127
00:35:56,476 --> 00:35:58,156
最后也具有最高的


1128
00:35:58,156 --> 00:35:58,796
概率


1129
00:35:58,896 --> 00:36:00,916
这是为什么 因为双字


1130
00:36:00,916 --> 00:36:02,506
说明的概率


1131
00:36:02,536 --> 00:36:04,516
只是其中两个单词


1132
00:36:04,516 --> 00:36:05,706
概率的


1133
00:36:05,706 --> 00:36:06,006
乘积


1134
00:36:07,116 --> 00:36:08,886
这就是我们如何获得这三个的最好


1135
00:36:08,886 --> 00:36:09,396
方法


1136
00:36:09,696 --> 00:36:11,226
然后我们留下它们并


1137
00:36:11,226 --> 00:36:12,836.
继续下一个迭代


1138
00:36:13,186 --> 00:36:14,406
而在下一次迭代中


1139
00:36:14,406 --> 00:36:15,936
我们只需为已有说明文字


1140
00:36:15,936 --> 00:36:17,536
再添加一个单词


1141
00:36:17,846 --> 00:36:18,806
这样就有了三字说明


1142
00:36:19,206 --> 00:36:19,996
然后我们计算这些


1143
00:36:19,996 --> 00:36:21,836
说明文字的概率


1144
00:36:21,836 --> 00:36:22,886
并挑选三个概率最高的


1145
00:36:23,936 --> 00:36:25,106
我们继续进行下一次


1146
00:36:25,106 --> 00:36:27,026
迭代 只需再添加


1147
00:36:27,026 --> 00:36:28,746
一个词到


1148
00:36:28,746 --> 00:36:29,186
文字说明中


1149
00:36:29,186 --> 00:36:30,566
然后我们有了四字文字说明


1150
00:36:30,976 --> 00:36:31,876
然后我们计算


1151
00:36:31,926 --> 00:36:33,186
所有这些文字说明的


1152
00:36:33,236 --> 00:36:34,546
概率 并挑选概率


1153
00:36:34,606 --> 00:36:34,816
最高的三个


1154
00:36:36,176 --> 00:36:37,306
等等 我觉得你已经


1155
00:36:37,306 --> 00:36:37,646
了解这个方法了


1156
00:36:37,866 --> 00:36:38,936
那就让我们跳到最后吧


1157
00:36:39,296 --> 00:36:41,416
所以最后 我们得到了三个


1158
00:36:41,416 --> 00:36:43,506
最好的文字说明来匹配


1159
00:36:43,506 --> 00:36:43,936
这个特定的图象


1160
00:36:43,936 --> 00:36:45,906
而其中最好的是一个男人


1161
00:36:45,906 --> 00:36:47,426
踏着冲浪板冲浪


1162
00:36:47,656 --> 00:36:48,616
我觉得意思已经非常接近了


1163
00:36:50,966 --> 00:36:52,346
所以现在我们来


1164
00:36:52,346 --> 00:36:52,726
演示一下


1165
00:36:53,508 --> 00:36:55,508
[掌声] 


1166
00:36:58,476 --> 00:37:00,116
所以现在我们来做一个


1167
00:37:00,606 --> 00:37:02,206
这个字幕网络的演示


1168
00:37:03,346 --> 00:37:04,856
我们在这里收集了


1169
00:37:04,856 --> 00:37:07,156
一些图像 一旦我点击


1170
00:37:07,156 --> 00:37:09,036
一张图像 CNN 


1171
00:37:09,136 --> 00:37:10,826
就会运行并确定


1172
00:37:10,826 --> 00:37:12,526
图像中描绘的内容


1173
00:37:12,526 --> 00:37:14,046
然后 RNN 将运行


1174
00:37:14,046 --> 00:37:15,226
并生成实际的说明文字


1175
00:37:15,356 --> 00:37:16,036
所以让我们试试吧


1176
00:37:17,826 --> 00:37:19,446
>>一个男人踏着


1177
00:37:19,446 --> 00:37:19,766
冲浪板冲浪


1178
00:37:19,766 --> 00:37:22,356
>>这个我们已经知道了


1179
00:37:23,526 --> 00:37:24,566
现在让我们试试另一张


1180
00:37:24,996 --> 00:37:26,536
>>一辆旧卡车停放在


1181
00:37:26,536 --> 00:37:27,106
野外


1182
00:37:27,626 --> 00:37:28,936
>>所以网络实际上知道


1183
00:37:28,976 --> 00:37:30,356
这是一辆旧卡车 


1184
00:37:30,356 --> 00:37:31,786
它是停放着的 不动的


1185
00:37:31,966 --> 00:37:33,336
我觉得这非常


1186
00:37:33,556 --> 00:37:34,156
令人惊叹


1187
00:37:34,786 --> 00:37:35,656
再试一次


1188
00:37:37,026 --> 00:37:38,496
>>一只黑白花纹的狗


1189
00:37:38,496 --> 00:37:39,086
躺在草地上


1190
00:37:39,796 --> 00:37:40,896
>>所以网络知道


1191
00:37:40,896 --> 00:37:42,176
这是一只黑白色的狗 


1192
00:37:42,176 --> 00:37:43,636
它躺在草地上 


1193
00:37:44,326 --> 00:37:45,106
并没有跑


1194
00:37:45,236 --> 00:37:46,356
没有走路


1195
00:37:46,726 --> 00:37:47,876
也没有坐着 


1196
00:37:48,336 --> 00:37:50,266
而是躺在草地上


1197
00:37:50,766 --> 00:37:52,796
太酷了


1198
00:37:53,516 --> 00:37:57,786
[掌声] 


1199
00:37:58,286 --> 00:37:58,726
谢谢


1200
00:37:59,306 --> 00:38:01,166
借着这个说明 我们来


1201
00:38:01,236 --> 00:38:01,586
总结一下


1202
00:38:02,066 --> 00:38:03,536
所以在本次会议中 


1203
00:38:03,536 --> 00:38:05,246
我们讨论了今年在


1204
00:38:05,276 --> 00:38:07,006
MPS 框架中


1205
00:38:07,336 --> 00:38:08,206
添加的所有新原语。


1206
00:38:08,586 --> 00:38:10,236
我们扩大了对


1207
00:38:10,236 --> 00:38:12,386
图像处理原语和


1208
00:38:12,786 --> 00:38:13,736
卷积神经网络的


1209
00:38:13,736 --> 00:38:14,136
支持


1210
00:38:15,006 --> 00:38:16,596
我们还增加了对


1211
00:38:16,596 --> 00:38:18,886
线性代数和循环


1212
00:38:18,886 --> 00:38:22,226
神经网络的支持


1213
00:38:23,096 --> 00:38:24,666
该框架针对针对


1214
00:38:24,666 --> 00:38:26,146
iOS 进行了优化 正如我所说的那样


1215
00:38:26,596 --> 00:38:29,226
现在这些原语也都在


1216
00:38:29,226 --> 00:38:30,016
Mac 上可用


1217
00:38:31,116 --> 00:38:32,416
我们还讨论了新的


1218
00:38:32,416 --> 00:38:34,676
神经网络图像 API 


1219
00:38:34,676 --> 00:38:36,406
并向你展示了如何


1220
00:38:36,406 --> 00:38:38,336
在 GPU 上构建和运行


1221
00:38:38,336 --> 00:38:39,666
你的网络


1222
00:38:40,426 --> 00:38:42,186
而且 这使我们有可能


1223
00:38:42,186 --> 00:38:43,586
在不同的 GPU 上


1224
00:38:43,666 --> 00:38:45,346
为你的网络提供


1225
00:38:45,346 --> 00:38:46,336
最佳性能


1226
00:38:46,336 --> 00:38:49,776
我们希望大家能够


1227
00:38:49,776 --> 00:38:51,976
使用所有这些新功能 


1228
00:38:51,976 --> 00:38:53,526
来创建非常好的应用程序


1229
00:38:53,526 --> 00:38:55,836
并告诉我们


1230
00:38:56,116 --> 00:38:57,296
所以 请查看 Metal 2 相关的


1231
00:38:57,296 --> 00:38:58,856
会议和有关


1232
00:38:58,856 --> 00:39:01,186
核心 ML


1233
00:39:01,676 --> 00:39:03,006
Accelerate 和 Vision 


1234
00:39:03,006 --> 00:39:03,486
框架的会议


1235
00:39:04,716 --> 00:39:06,036
有关此会议的更多信息


1236
00:39:06,096 --> 00:39:07,636
以及示例代码的链接 


1237
00:39:07,706 --> 00:39:09,936
请登陆我们的


1238
00:39:09,986 --> 00:39:11,426
开发者网站查看这个链接


1239
00:39:11,426 --> 00:39:14,276
非常感谢大家的


1240
00:39:14,276 --> 00:39:15,636
出席 祝大家在


1241
00:39:15,636 --> 00:39:15,846
WWDC 大会期间有更多收获


1242
00:39:16,516 --> 00:39:20,500
[掌声] 

